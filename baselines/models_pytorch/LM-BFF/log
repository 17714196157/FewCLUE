{'time': '2021-07-22 22:16:15.921045', 'iflytek_dev_eval_loss': 2.890838146209717, 'iflytek_dev_eval_acc': 0.41304347826086957, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-13-30_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:19:01.277648', 'iflytek_dev_eval_loss': 2.8512048721313477, 'iflytek_dev_eval_acc': 0.4144927536231884, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-16-32_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:21:46.053893', 'iflytek_dev_eval_loss': 2.8141233921051025, 'iflytek_dev_eval_acc': 0.4072463768115942, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-19-18_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:24:29.481376', 'iflytek_dev_eval_loss': 2.828399658203125, 'iflytek_dev_eval_acc': 0.41739130434782606, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-22-02_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:27:12.206752', 'iflytek_dev_eval_loss': 2.8468804359436035, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-24-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*app*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:29:54.017684', 'iflytek_dev_eval_loss': 2.7787249088287354, 'iflytek_dev_eval_acc': 0.41594202898550725, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-27-29_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*微*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:32:35.551783', 'iflytek_dev_eval_loss': 2.7994930744171143, 'iflytek_dev_eval_acc': 0.3927536231884058, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-30-10_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:35:15.131286', 'iflytek_dev_eval_loss': 2.919083833694458, 'iflytek_dev_eval_acc': 0.4, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-32-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:37:58.459800', 'iflytek_dev_eval_loss': 2.842184066772461, 'iflytek_dev_eval_acc': 0.4144927536231884, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-35-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:40:31.526826', 'eprstmt_dev_eval_loss': 1.8157610893249512, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-39-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:41:25.561870', 'iflytek_dev_eval_loss': 2.7992193698883057, 'iflytek_dev_eval_acc': 0.4072463768115942, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-38-15_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:42:03.989767', 'eprstmt_dev_eval_loss': 1.795954704284668, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-40-38_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*！*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:43:43.477462', 'eprstmt_dev_eval_loss': 1.9454832077026367, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-42-10_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:45:35.836265', 'eprstmt_dev_eval_loss': 2.3147027492523193, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-43-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*啊*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:45:33.489578', 'iflytek_dev_eval_loss': 2.7955620288848877, 'iflytek_dev_eval_acc': 0.39420289855072466, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-41-50_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*与*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:47:03.235652', 'eprstmt_dev_eval_loss': 1.822170615196228, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-45-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*蛮*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:49:08.114080', 'eprstmt_dev_eval_loss': 2.3913564682006836, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-47-10_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:49:39.645172', 'iflytek_dev_eval_loss': 2.7985260486602783, 'iflytek_dev_eval_acc': 0.4101449275362319, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-45-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:50:34.053858', 'eprstmt_dev_eval_loss': 2.48295521736145, 'eprstmt_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-49-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:52:48.303087', 'eprstmt_dev_eval_loss': 2.087303876876831, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-50-41_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*吧*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:54:14.612767', 'tnews_dev_eval_loss': 2.5175843238830566, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-51-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:54:15.115055', 'iflytek_dev_eval_loss': 2.737488031387329, 'iflytek_dev_eval_acc': 0.40869565217391307, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-50-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:55:08.310848', 'eprstmt_dev_eval_loss': 1.5896295309066772, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-53-03_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*真*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:56:33.823653', 'tnews_dev_eval_loss': 2.662409543991089, 'tnews_dev_eval_acc': 0.4875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-54-29_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:57:27.285922', 'eprstmt_dev_eval_loss': 1.455120325088501, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-55-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:59:01.967246', 'tnews_dev_eval_loss': 3.139256238937378, 'tnews_dev_eval_acc': 0.49166666666666664, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-56-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:59:20.668107', 'iflytek_dev_eval_loss': 2.688037157058716, 'iflytek_dev_eval_acc': 0.4289855072463768, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-54-41_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 22:59:47.528049', 'eprstmt_dev_eval_loss': 2.0405611991882324, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-57-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*呀*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:01:11.752146', 'tnews_dev_eval_loss': 3.072042942047119, 'tnews_dev_eval_acc': 0.49166666666666664, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-59-16_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:02:03.758066', 'eprstmt_dev_eval_loss': 2.0685806274414062, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-59-57_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:03:43.371498', 'tnews_dev_eval_loss': 2.6635000705718994, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-01-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:04:28.585599', 'eprstmt_dev_eval_loss': 2.5446524620056152, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-02-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*劲*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:04:21.393084', 'iflytek_dev_eval_loss': 2.681861162185669, 'iflytek_dev_eval_acc': 0.427536231884058, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_22-59-44_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:05:58.945945', 'tnews_dev_eval_loss': 2.4888436794281006, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-03-54_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:06:30.053646', 'eprstmt_dev_eval_loss': 2.312429904937744, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-04-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*蛮*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:08:33.423908', 'tnews_dev_eval_loss': 2.765594720840454, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-06-12_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:08:47.504305', 'eprstmt_dev_eval_loss': 2.1898176670074463, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-06-40_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:09:14.811399', 'iflytek_dev_eval_loss': 2.560652017593384, 'iflytek_dev_eval_acc': 0.4434782608695652, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-04-48_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:10:51.571040', 'tnews_dev_eval_loss': 2.8276259899139404, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-08-44_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:10:59.930543', 'eprstmt_dev_eval_loss': 1.0100213289260864, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-08-57_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:13:20.882976', 'tnews_dev_eval_loss': 2.759843349456787, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-11-00_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:13:22.828583', 'eprstmt_dev_eval_loss': 0.8472210764884949, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-11-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:14:05.435979', 'iflytek_dev_eval_loss': 2.6627097129821777, 'iflytek_dev_eval_acc': 0.4260869565217391, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-09-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:15:38.375939', 'eprstmt_dev_eval_loss': 0.7552520036697388, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-13-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:15:42.694023', 'tnews_dev_eval_loss': 2.6128005981445312, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-13-32_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:17:56.488870', 'eprstmt_dev_eval_loss': 1.9620134830474854, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-15-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*。*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:18:13.897847', 'tnews_dev_eval_loss': 3.0143606662750244, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-15-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:18:56.735674', 'iflytek_dev_eval_loss': 2.5366714000701904, 'iflytek_dev_eval_acc': 0.4420289855072464, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-14-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:20:05.951168', 'eprstmt_dev_eval_loss': 1.8832907676696777, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-18-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*太*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:20:30.943275', 'tnews_dev_eval_loss': 2.8010644912719727, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-18-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*啊*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:22:22.954525', 'eprstmt_dev_eval_loss': 0.8592633605003357, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-20-16_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*蛮*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:22:58.205785', 'tnews_dev_eval_loss': 2.5685949325561523, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-20-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*与*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:23:54.292026', 'iflytek_dev_eval_loss': 2.7371973991394043, 'iflytek_dev_eval_acc': 0.4217391304347826, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-19-27_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:24:41.621307', 'eprstmt_dev_eval_loss': 1.3462672233581543, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-22-35_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*啊*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:25:13.877861', 'tnews_dev_eval_loss': 2.638313055038452, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-23-09_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*（*mask*mask*）*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:27:04.550120', 'eprstmt_dev_eval_loss': 1.4780406951904297, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-24-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*！*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:27:50.189236', 'tnews_dev_eval_loss': 2.7708022594451904, 'tnews_dev_eval_acc': 0.49166666666666664, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-25-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*？*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:28:55.549549', 'iflytek_dev_eval_loss': 2.654137372970581, 'iflytek_dev_eval_acc': 0.43768115942028984, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-24-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:29:25.736362', 'eprstmt_dev_eval_loss': 1.3433680534362793, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-27-15_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*用*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:30:07.194915', 'tnews_dev_eval_loss': 3.331007957458496, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-28-03_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:31:47.214818', 'eprstmt_dev_eval_loss': 1.4444509744644165, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-29-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:32:31.697122', 'tnews_dev_eval_loss': 3.384831666946411, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-30-18_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:34:11.830429', 'eprstmt_dev_eval_loss': 1.1665912866592407, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-31-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:34:04.131260', 'iflytek_dev_eval_loss': 2.5191118717193604, 'iflytek_dev_eval_acc': 0.45362318840579713, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-29-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*。*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:34:50.018494', 'tnews_dev_eval_loss': 2.6917266845703125, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-32-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:36:16.163291', 'eprstmt_dev_eval_loss': 1.3732935190200806, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-34-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*吧*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:37:18.651472', 'tnews_dev_eval_loss': 3.0185418128967285, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-35-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:38:33.980500', 'eprstmt_dev_eval_loss': 1.3823881149291992, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-36-29_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*我*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:39:04.089041', 'iflytek_dev_eval_loss': 2.574387788772583, 'iflytek_dev_eval_acc': 0.43043478260869567, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-34-28_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:39:51.818707', 'tnews_dev_eval_loss': 3.6452081203460693, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-37-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*《*mask*mask*》*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:40:37.962616', 'eprstmt_dev_eval_loss': 1.8574855327606201, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-38-44_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*劲*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:42:19.992082', 'tnews_dev_eval_loss': 3.1731810569763184, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-40-02_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*[*mask*mask*]*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:43:02.452123', 'eprstmt_dev_eval_loss': 1.1977958679199219, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-40-48_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-27254', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*还*mask*吧*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:44:06.934860', 'iflytek_dev_eval_loss': 2.599776268005371, 'iflytek_dev_eval_acc': 0.4405797101449275, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-39-34_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*爱*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:44:49.990952', 'tnews_dev_eval_loss': 2.781043529510498, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-42-34_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:45:12.600854', 'eprstmt_dev_eval_loss': 0.8351480960845947, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-43-15_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:47:22.502476', 'tnews_dev_eval_loss': 3.270667552947998, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-45-00_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:47:34.170347', 'eprstmt_dev_eval_loss': 1.2201522588729858, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-45-22_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*！*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:49:06.144608', 'iflytek_dev_eval_loss': 2.6384849548339844, 'iflytek_dev_eval_acc': 0.4289855072463768, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-44-38_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*网*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:49:55.119522', 'tnews_dev_eval_loss': 3.081155300140381, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-47-34_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*net*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:49:58.039342', 'eprstmt_dev_eval_loss': 1.1644678115844727, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-47-44_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*啊*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:52:23.573445', 'eprstmt_dev_eval_loss': 1.5216636657714844, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-50-07_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:52:27.085277', 'tnews_dev_eval_loss': 2.851665735244751, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-50-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:54:05.851969', 'iflytek_dev_eval_loss': 2.604132652282715, 'iflytek_dev_eval_acc': 0.43333333333333335, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-49-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*(*mask*mask*)*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:54:52.927382', 'eprstmt_dev_eval_loss': 1.2549843788146973, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-52-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*蛮*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:54:55.224683', 'tnews_dev_eval_loss': 3.476828098297119, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-52-40_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:57:20.762921', 'eprstmt_dev_eval_loss': 0.7569445967674255, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-55-03_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:57:20.269940', 'tnews_dev_eval_loss': 2.530548572540283, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-55-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:58:59.446882', 'iflytek_dev_eval_loss': 2.7353622913360596, 'iflytek_dev_eval_acc': 0.4217391304347826, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-54-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*上*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:59:48.111708', 'eprstmt_dev_eval_loss': 1.3495150804519653, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-57-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*吧*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-22 23:59:54.407886', 'tnews_dev_eval_loss': 2.98584246635437, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-57-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:02:13.136327', 'eprstmt_dev_eval_loss': 1.488568902015686, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-59-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*呀*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:02:24.008276', 'tnews_dev_eval_loss': 3.623612880706787, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-00-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:04:02.715974', 'iflytek_dev_eval_loss': 2.5805304050445557, 'iflytek_dev_eval_acc': 0.45217391304347826, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul22_23-59-30_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:04:40.324107', 'eprstmt_dev_eval_loss': 1.0992813110351562, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-02-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*真*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:04:49.403708', 'tnews_dev_eval_loss': 3.184525966644287, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-02-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7596', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*:*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:07:05.478290', 'eprstmt_dev_eval_loss': 1.1051464080810547, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-04-50_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:07:19.652834', 'tnews_dev_eval_loss': 2.8900866508483887, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-05-00_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:09:07.311929', 'iflytek_dev_eval_loss': 2.955597162246704, 'iflytek_dev_eval_acc': 0.42028985507246375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-04-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:09:33.007802', 'eprstmt_dev_eval_loss': 1.120842695236206, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-07-17_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:09:46.085202', 'tnews_dev_eval_loss': 2.906921148300171, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-07-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:11:58.592230', 'eprstmt_dev_eval_loss': 1.9515085220336914, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-09-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*用*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:12:14.784090', 'tnews_dev_eval_loss': 2.9612627029418945, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-09-56_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:14:27.112218', 'eprstmt_dev_eval_loss': 1.528017520904541, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-12-09_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*~*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:14:18.268366', 'iflytek_dev_eval_loss': 2.690108299255371, 'iflytek_dev_eval_acc': 0.4420289855072464, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-09-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:14:42.677427', 'tnews_dev_eval_loss': 2.720844030380249, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-12-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:16:58.686182', 'eprstmt_dev_eval_loss': 0.8964215517044067, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-14-40_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*蛮*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:17:10.460824', 'tnews_dev_eval_loss': 2.745340585708618, 'tnews_dev_eval_acc': 0.5791666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-14-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:19:29.370639', 'eprstmt_dev_eval_loss': 1.1361854076385498, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-17-10_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*哦*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:19:23.583750', 'iflytek_dev_eval_loss': 2.7071480751037598, 'iflytek_dev_eval_acc': 0.41739130434782606, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-14-41_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19546', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:19:37.797486', 'tnews_dev_eval_loss': 2.991558790206909, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-17-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:22:01.931665', 'eprstmt_dev_eval_loss': 1.4328012466430664, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-19-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:22:06.404527', 'tnews_dev_eval_loss': 3.3396971225738525, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-19-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:24:36.024880', 'eprstmt_dev_eval_loss': 1.6600557565689087, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-22-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:24:40.534811', 'tnews_dev_eval_loss': 3.304251194000244, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-22-16_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:24:30.339416', 'iflytek_dev_eval_loss': 2.938178777694702, 'iflytek_dev_eval_acc': 0.391304347826087, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-19-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:27:07.357475', 'eprstmt_dev_eval_loss': 1.621321439743042, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-24-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:27:07.716351', 'tnews_dev_eval_loss': 2.89715576171875, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-24-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*纯*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:29:38.124686', 'eprstmt_dev_eval_loss': 1.5540128946304321, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-27-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*蛮*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:29:42.353927', 'tnews_dev_eval_loss': 2.69387149810791, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-27-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:29:32.161438', 'iflytek_dev_eval_loss': 2.9287519454956055, 'iflytek_dev_eval_acc': 0.38115942028985506, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-24-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:32:10.510383', 'eprstmt_dev_eval_loss': 1.6331759691238403, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-29-50_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*太*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:32:13.529805', 'tnews_dev_eval_loss': 2.4057302474975586, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-29-54_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:34:37.859505', 'eprstmt_dev_eval_loss': 1.5015548467636108, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-32-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*啊*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:34:29.592659', 'iflytek_dev_eval_loss': 2.8793771266937256, 'iflytek_dev_eval_acc': 0.39710144927536234, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-29-54_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*app*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:34:43.893967', 'tnews_dev_eval_loss': 2.822045087814331, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-32-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*纯*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:37:07.649981', 'eprstmt_dev_eval_loss': 1.688828706741333, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-34-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*。*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:37:11.805711', 'tnews_dev_eval_loss': 2.7153382301330566, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-34-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*啊*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:39:42.467454', 'eprstmt_dev_eval_loss': 1.2217994928359985, 'eprstmt_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-37-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*用*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:39:40.842335', 'tnews_dev_eval_loss': 2.705125331878662, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-37-22_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*？*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:39:31.933744', 'iflytek_dev_eval_loss': 2.948354959487915, 'iflytek_dev_eval_acc': 0.3753623188405797, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-34-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:42:17.626172', 'eprstmt_dev_eval_loss': 2.046943187713623, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-39-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*！*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:42:18.391018', 'tnews_dev_eval_loss': 3.219884157180786, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-39-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*（*mask*mask*）*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:44:43.743296', 'eprstmt_dev_eval_loss': 1.25100839138031, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-42-30_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:44:32.206872', 'iflytek_dev_eval_loss': 2.9381825923919678, 'iflytek_dev_eval_acc': 0.3826086956521739, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-39-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:44:51.550344', 'tnews_dev_eval_loss': 3.4760711193084717, 'tnews_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-42-30_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:47:09.136734', 'eprstmt_dev_eval_loss': 1.6042016744613647, 'eprstmt_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-44-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*还*mask*吧*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:47:15.832608', 'tnews_dev_eval_loss': 2.822277784347534, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-44-59_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:49:40.366451', 'eprstmt_dev_eval_loss': 1.4805070161819458, 'eprstmt_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-47-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:49:37.074404', 'iflytek_dev_eval_loss': 2.8511714935302734, 'iflytek_dev_eval_acc': 0.3898550724637681, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-44-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*微*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:49:48.522170', 'tnews_dev_eval_loss': 2.5250930786132812, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-47-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:52:12.552647', 'eprstmt_dev_eval_loss': 1.6011600494384766, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-49-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*吧*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:52:15.116461', 'tnews_dev_eval_loss': 3.177666664123535, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-49-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:54:41.438953', 'eprstmt_dev_eval_loss': 1.2533143758773804, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-52-23_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*还*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:54:38.461991', 'iflytek_dev_eval_loss': 2.9078831672668457, 'iflytek_dev_eval_acc': 0.38405797101449274, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-49-59_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:54:51.003804', 'tnews_dev_eval_loss': 2.763747453689575, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-52-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*《*mask*mask*》*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:57:12.459053', 'eprstmt_dev_eval_loss': 1.1628952026367188, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-54-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1770', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*是*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:57:19.589739', 'tnews_dev_eval_loss': 3.3533616065979004, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-55-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*[*mask*mask*]*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:59:50.647854', 'eprstmt_dev_eval_loss': 1.1876314878463745, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-57-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:59:43.853546', 'iflytek_dev_eval_loss': 2.9434947967529297, 'iflytek_dev_eval_acc': 0.3695652173913043, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-55-00_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 00:59:55.001986', 'tnews_dev_eval_loss': 3.058612585067749, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_00-57-29_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:02:21.208628', 'eprstmt_dev_eval_loss': 1.2592151165008545, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-00-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*！*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:02:23.740798', 'tnews_dev_eval_loss': 2.7865490913391113, 'tnews_dev_eval_acc': 0.5541666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-00-06_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*net*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:04:51.532612', 'eprstmt_dev_eval_loss': 0.9413923621177673, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-02-32_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*啊*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:04:45.037672', 'iflytek_dev_eval_loss': 2.8483386039733887, 'iflytek_dev_eval_acc': 0.38405797101449274, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-00-06_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:04:58.386673', 'tnews_dev_eval_loss': 2.595867395401001, 'tnews_dev_eval_acc': 0.5666666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-02-34_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:07:30.588104', 'eprstmt_dev_eval_loss': 0.7881757020950317, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-05-06_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:07:31.654617', 'tnews_dev_eval_loss': 3.078749179840088, 'tnews_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-05-07_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:09:54.952685', 'eprstmt_dev_eval_loss': 0.7961665391921997, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-07-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*蛮*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:09:46.220623', 'iflytek_dev_eval_loss': 2.9752426147460938, 'iflytek_dev_eval_acc': 0.37971014492753624, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-05-07_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:10:01.030346', 'tnews_dev_eval_loss': 3.1242268085479736, 'tnews_dev_eval_acc': 0.5708333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-07-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:12:26.407610', 'eprstmt_dev_eval_loss': 0.7402108311653137, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-10-07_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:12:30.554219', 'tnews_dev_eval_loss': 3.4287757873535156, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-10-09_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:14:55.693089', 'eprstmt_dev_eval_loss': 0.6544727683067322, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-12-38_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*真*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:14:49.221514', 'iflytek_dev_eval_loss': 2.8308746814727783, 'iflytek_dev_eval_acc': 0.37971014492753624, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-10-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*与*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:15:01.099432', 'tnews_dev_eval_loss': 2.8409345149993896, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-12-40_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:17:20.690579', 'eprstmt_dev_eval_loss': 0.8489770889282227, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-15-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*呀*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:17:26.843782', 'tnews_dev_eval_loss': 2.830467939376831, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-15-11_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:19:52.646847', 'eprstmt_dev_eval_loss': 0.7701571583747864, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-17-32_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*用*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:19:57.145827', 'tnews_dev_eval_loss': 2.8642661571502686, 'tnews_dev_eval_acc': 0.5916666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-17-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-15901', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*:*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:19:57.881679', 'iflytek_dev_eval_loss': 2.919529438018799, 'iflytek_dev_eval_acc': 0.3782608695652174, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-15-11_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:22:22.633593', 'eprstmt_dev_eval_loss': 1.1783969402313232, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-20-06_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:22:27.276133', 'tnews_dev_eval_loss': 2.1844656467437744, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-20-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:24:55.550273', 'eprstmt_dev_eval_loss': 0.9056651592254639, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-22-34_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*吧*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:25:02.419225', 'tnews_dev_eval_loss': 2.111051082611084, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-22-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:24:59.138433', 'iflytek_dev_eval_loss': 2.816783905029297, 'iflytek_dev_eval_acc': 0.3898550724637681, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-20-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:27:13.581783', 'eprstmt_dev_eval_loss': 1.1659942865371704, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-25-09_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:27:28.944856', 'tnews_dev_eval_loss': 2.4960241317749023, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-25-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:29:35.214359', 'eprstmt_dev_eval_loss': 1.2503055334091187, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-27-27_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*哦*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:30:04.266014', 'tnews_dev_eval_loss': 2.5556390285491943, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-27-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:30:01.787327', 'iflytek_dev_eval_loss': 2.8126003742218018, 'iflytek_dev_eval_acc': 0.39420289855072466, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-25-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:31:41.979977', 'eprstmt_dev_eval_loss': 1.1405457258224487, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-29-46_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*~*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:32:30.559397', 'tnews_dev_eval_loss': 2.009676456451416, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-30-17_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:34:02.350491', 'eprstmt_dev_eval_loss': 1.1227869987487793, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-31-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:35:04.270702', 'tnews_dev_eval_loss': 2.162806749343872, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-32-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:35:00.807790', 'iflytek_dev_eval_loss': 2.793242931365967, 'iflytek_dev_eval_acc': 0.3869565217391304, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-30-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在线*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:36:03.175888', 'eprstmt_dev_eval_loss': 1.2452013492584229, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-34-15_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:37:33.152491', 'tnews_dev_eval_loss': 2.6906521320343018, 'tnews_dev_eval_acc': 0.475, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-35-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:38:21.924364', 'eprstmt_dev_eval_loss': 1.4756782054901123, 'eprstmt_dev_eval_acc': 0.78125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-36-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:40:13.023020', 'tnews_dev_eval_loss': 2.2396929264068604, 'tnews_dev_eval_acc': 0.475, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-37-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:40:06.270066', 'iflytek_dev_eval_loss': 2.7438180446624756, 'iflytek_dev_eval_acc': 0.4144927536231884, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-35-26_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:40:43.925632', 'eprstmt_dev_eval_loss': 1.1772706508636475, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-38-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:42:39.102284', 'tnews_dev_eval_loss': 1.931383490562439, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-40-28_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:43:01.645002', 'eprstmt_dev_eval_loss': 0.7909361720085144, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-40-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*。*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:45:15.312145', 'tnews_dev_eval_loss': 2.1524903774261475, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-42-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:45:28.385396', 'eprstmt_dev_eval_loss': 1.0589388608932495, 'eprstmt_dev_eval_acc': 0.8125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-43-12_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*蛮*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:45:18.306485', 'iflytek_dev_eval_loss': 2.76370906829834, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-40-32_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:47:46.407147', 'tnews_dev_eval_loss': 2.179570436477661, 'tnews_dev_eval_acc': 0.49583333333333335, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-45-29_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:47:49.955691', 'eprstmt_dev_eval_loss': 0.9388420581817627, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-45-38_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*！*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:50:23.141574', 'eprstmt_dev_eval_loss': 1.0891951322555542, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-47-59_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*啊*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:50:16.702313', 'iflytek_dev_eval_loss': 2.735823154449463, 'iflytek_dev_eval_acc': 0.41739130434782606, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-45-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:50:29.327379', 'tnews_dev_eval_loss': 1.9550832509994507, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-47-57_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*啊*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:52:35.278941', 'eprstmt_dev_eval_loss': 0.6619890928268433, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-50-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*太*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:52:49.097738', 'tnews_dev_eval_loss': 1.9361516237258911, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-50-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*（*mask*mask*）*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:55:01.122730', 'eprstmt_dev_eval_loss': 1.2259576320648193, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-52-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*用*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:55:20.821889', 'tnews_dev_eval_loss': 2.1562654972076416, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-52-59_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*？*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:55:22.690300', 'iflytek_dev_eval_loss': 2.8272860050201416, 'iflytek_dev_eval_acc': 0.3782608695652174, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-50-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:57:08.690468', 'eprstmt_dev_eval_loss': 1.0064597129821777, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-55-12_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:57:35.909388', 'tnews_dev_eval_loss': 2.27700138092041, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-55-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*？*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 01:59:36.626169', 'eprstmt_dev_eval_loss': 0.8472173810005188, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-57-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*蛮*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:00:00.571019', 'tnews_dev_eval_loss': 1.7686500549316406, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-57-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:00:18.665057', 'iflytek_dev_eval_loss': 2.7855591773986816, 'iflytek_dev_eval_acc': 0.4057971014492754, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-55-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:01:45.663961', 'eprstmt_dev_eval_loss': 1.091796875, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_01-59-49_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*还*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:02:12.143254', 'tnews_dev_eval_loss': 2.050091505050659, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-00-13_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:04:14.872978', 'eprstmt_dev_eval_loss': 1.095467448234558, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-01-57_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*.*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:04:40.386391', 'tnews_dev_eval_loss': 2.2597343921661377, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-02-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:05:12.191115', 'iflytek_dev_eval_loss': 2.7047231197357178, 'iflytek_dev_eval_acc': 0.4246376811594203, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-00-48_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:06:26.405595', 'eprstmt_dev_eval_loss': 1.1365931034088135, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-04-27_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*真*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:06:56.217238', 'tnews_dev_eval_loss': 2.610365390777588, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-04-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:08:50.847272', 'eprstmt_dev_eval_loss': 1.1002590656280518, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-06-38_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*呀*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:09:21.672750', 'tnews_dev_eval_loss': 1.7004588842391968, 'tnews_dev_eval_acc': 0.5583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-07-07_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*《*mask*mask*》*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:10:12.233738', 'iflytek_dev_eval_loss': 2.6632940769195557, 'iflytek_dev_eval_acc': 0.42028985507246375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-05-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*。*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:11:08.896319', 'eprstmt_dev_eval_loss': 0.5180119872093201, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-09-03_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:11:29.308432', 'tnews_dev_eval_loss': 1.7824922800064087, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-09-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*[*mask*mask*]*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:13:26.696622', 'eprstmt_dev_eval_loss': 1.121057391166687, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-11-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*！*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:13:58.393319', 'tnews_dev_eval_loss': 1.9973504543304443, 'tnews_dev_eval_acc': 0.5416666666666666, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-11-40_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:15:10.319132', 'iflytek_dev_eval_loss': 2.781778335571289, 'iflytek_dev_eval_acc': 0.4, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-10-44_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*爱*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:15:55.677175', 'eprstmt_dev_eval_loss': 1.0583003759384155, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-13-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*啊*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:16:10.524109', 'tnews_dev_eval_loss': 1.7849006652832031, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-14-09_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:18:16.980965', 'eprstmt_dev_eval_loss': 0.3428921401500702, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-16-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:18:37.170904', 'tnews_dev_eval_loss': 1.7921106815338135, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-16-21_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*net*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:20:14.784277', 'iflytek_dev_eval_loss': 2.877580165863037, 'iflytek_dev_eval_acc': 0.3869565217391304, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-15-41_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*上*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:20:32.961395', 'eprstmt_dev_eval_loss': 0.7861431837081909, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-18-27_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*吧*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:21:03.395860', 'tnews_dev_eval_loss': 2.3512277603149414, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-18-49_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:22:53.540215', 'eprstmt_dev_eval_loss': 0.2147088348865509, 'eprstmt_dev_eval_acc': 0.96875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-20-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*挺*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:23:26.899602', 'tnews_dev_eval_loss': 2.1353578567504883, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-21-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:25:33.578736', 'eprstmt_dev_eval_loss': 0.1996062994003296, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-23-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*了*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:25:34.121288', 'iflytek_dev_eval_loss': 2.689631700515747, 'iflytek_dev_eval_acc': 0.4246376811594203, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-20-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:25:47.192322', 'tnews_dev_eval_loss': 2.2283880710601807, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-23-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:27:42.365469', 'eprstmt_dev_eval_loss': 1.0472530126571655, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-25-48_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*呀*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:28:11.886224', 'tnews_dev_eval_loss': 2.7888596057891846, 'tnews_dev_eval_acc': 0.5083333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-25-56_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:30:03.871735', 'eprstmt_dev_eval_loss': 0.7877081036567688, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-27-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*蛮*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:30:46.994565', 'tnews_dev_eval_loss': 2.3294646739959717, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-28-23_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:30:35.060899', 'iflytek_dev_eval_loss': 2.7604682445526123, 'iflytek_dev_eval_acc': 0.4072463768115942, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-25-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*网*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:32:11.878272', 'eprstmt_dev_eval_loss': 0.2921099066734314, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-30-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*太*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:33:12.044069', 'tnews_dev_eval_loss': 2.0035829544067383, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-31-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-2569', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*:*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:34:23.630257', 'eprstmt_dev_eval_loss': 0.4739924669265747, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-32-23_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*劲*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:35:50.763517', 'tnews_dev_eval_loss': 2.2302584648132324, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-33-26_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:35:38.465463', 'iflytek_dev_eval_loss': 2.667293071746826, 'iflytek_dev_eval_acc': 0.41594202898550725, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-31-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*(*mask*mask*)*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:36:32.852858', 'eprstmt_dev_eval_loss': 0.34264034032821655, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-34-35_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*真*mask*。*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:38:20.204361', 'tnews_dev_eval_loss': 2.3163042068481445, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-36-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:38:54.050261', 'eprstmt_dev_eval_loss': 0.43327683210372925, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-36-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*的*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:40:53.714967', 'tnews_dev_eval_loss': 3.025956630706787, 'tnews_dev_eval_acc': 0.4583333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-38-32_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:40:49.768717', 'iflytek_dev_eval_loss': 2.7949774265289307, 'iflytek_dev_eval_acc': 0.40144927536231884, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-36-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:41:17.184581', 'eprstmt_dev_eval_loss': 1.1208925247192383, 'eprstmt_dev_eval_acc': 0.84375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-39-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*~*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:43:11.535603', 'tnews_dev_eval_loss': 2.5126123428344727, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-41-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:43:33.307617', 'eprstmt_dev_eval_loss': 0.4018048644065857, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-41-27_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*很*mask*用*sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:45:48.345616', 'tnews_dev_eval_loss': 2.2466843128204346, 'tnews_dev_eval_acc': 0.48333333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-43-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:46:01.650038', 'eprstmt_dev_eval_loss': 0.41056859493255615, 'eprstmt_dev_eval_acc': 0.96875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-43-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:45:59.963811', 'iflytek_dev_eval_loss': 3.008694648742676, 'iflytek_dev_eval_acc': 0.3884057971014493, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-41-14_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:48:08.519292', 'tnews_dev_eval_loss': 2.4054765701293945, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-46-02_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:48:11.476995', 'eprstmt_dev_eval_loss': 0.7328933477401733, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-46-11_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:50:37.834680', 'eprstmt_dev_eval_loss': 0.6517999172210693, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-48-23_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:50:40.640566', 'tnews_dev_eval_loss': 2.5688085556030273, 'tnews_dev_eval_acc': 0.49166666666666664, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-48-22_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:50:58.435170', 'iflytek_dev_eval_loss': 2.817023992538452, 'iflytek_dev_eval_acc': 0.3869565217391304, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-46-21_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24521', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:52:47.472553', 'eprstmt_dev_eval_loss': 1.0585663318634033, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-50-49_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*蛮*mask*的*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:52:54.101064', 'tnews_dev_eval_loss': 2.111753225326538, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-50-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:55:13.325622', 'eprstmt_dev_eval_loss': 0.5388680696487427, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-52-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*。*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:55:23.786723', 'tnews_dev_eval_loss': 2.2711730003356934, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-53-05_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*做*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:55:52.092916', 'iflytek_dev_eval_loss': 2.982126474380493, 'iflytek_dev_eval_acc': 0.3898550724637681, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-51-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:57:20.094845', 'eprstmt_dev_eval_loss': 0.12890449166297913, 'eprstmt_dev_eval_acc': 0.96875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-55-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*啊*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:57:39.842859', 'tnews_dev_eval_loss': 2.204866647720337, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-55-35_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 02:59:47.477433', 'eprstmt_dev_eval_loss': 0.12819920480251312, 'eprstmt_dev_eval_acc': 0.96875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-57-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*太*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:00:09.881135', 'tnews_dev_eval_loss': 2.592707395553589, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-57-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*看*mask*mask*。*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:00:53.516280', 'iflytek_dev_eval_loss': 2.763005256652832, 'iflytek_dev_eval_acc': 0.4, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_02-56-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:02:05.302618', 'eprstmt_dev_eval_loss': 0.2337847650051117, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-00-00_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*！*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:02:22.150535', 'tnews_dev_eval_loss': 2.0408151149749756, 'tnews_dev_eval_acc': 0.55, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-00-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*啊*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:04:24.433207', 'eprstmt_dev_eval_loss': 1.004028558731079, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-02-18_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*用*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:04:53.591001', 'tnews_dev_eval_loss': 2.6152701377868652, 'tnews_dev_eval_acc': 0.5333333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-02-33_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*（*mask*mask*）*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:05:51.571407', 'iflytek_dev_eval_loss': 2.743255615234375, 'iflytek_dev_eval_acc': 0.39855072463768115, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-01-26_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:06:46.901869', 'eprstmt_dev_eval_loss': 0.20171818137168884, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-04-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*吧*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:07:12.737453', 'tnews_dev_eval_loss': 2.2490203380584717, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-05-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*？*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:09:09.595751', 'eprstmt_dev_eval_loss': 0.4098067283630371, 'eprstmt_dev_eval_acc': 0.875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-06-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*了*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:09:44.984064', 'tnews_dev_eval_loss': 2.5873045921325684, 'tnews_dev_eval_acc': 0.5041666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-07-23_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*？*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:10:50.004380', 'iflytek_dev_eval_loss': 2.7389461994171143, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-06-22_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*app*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:11:30.802624', 'eprstmt_dev_eval_loss': 0.020175836980342865, 'eprstmt_dev_eval_acc': 1.0, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-09-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*劲*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:12:01.646427', 'tnews_dev_eval_loss': 2.1493115425109863, 'tnews_dev_eval_acc': 0.5208333333333334, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-09-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:13:53.580142', 'eprstmt_dev_eval_loss': 0.739944338798523, 'eprstmt_dev_eval_acc': 0.90625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-11-40_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*还*mask*吧*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:14:40.124294', 'tnews_dev_eval_loss': 2.0295779705047607, 'tnews_dev_eval_acc': 0.525, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-12-13_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:16:08.956661', 'eprstmt_dev_eval_loss': 0.4450126886367798, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-14-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*挺*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:15:57.759597', 'iflytek_dev_eval_loss': 2.7414095401763916, 'iflytek_dev_eval_acc': 0.4057971014492754, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-11-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:17:01.543822', 'tnews_dev_eval_loss': 2.1922504901885986, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-14-54_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:18:08.759282', 'eprstmt_dev_eval_loss': 0.37592294812202454, 'eprstmt_dev_eval_acc': 0.9375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-16-20_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-22812', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*我*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:19:08.822621', 'tnews_dev_eval_loss': 2.012254476547241, 'tnews_dev_eval_acc': 0.5375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-17-15_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:20:30.420046', 'iflytek_dev_eval_loss': 2.7497057914733887, 'iflytek_dev_eval_acc': 0.4072463768115942, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-16-24_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*微*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:20:55.549842', 'tnews_dev_eval_loss': 1.9987980127334595, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-19-18_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*《*mask*mask*》*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:22:39.714278', 'tnews_dev_eval_loss': 2.294114351272583, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-21-02_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*[*mask*mask*]*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:24:30.348059', 'tnews_dev_eval_loss': 2.0535364151000977, 'tnews_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-22-47_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:24:35.943780', 'iflytek_dev_eval_loss': 2.7027359008789062, 'iflytek_dev_eval_acc': 0.4028985507246377, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-20-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:25:56.535787', 'tnews_dev_eval_loss': 2.1492629051208496, 'tnews_dev_eval_acc': 0.5416666666666666, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-24-37_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:27:42.863835', 'tnews_dev_eval_loss': 2.223989963531494, 'tnews_dev_eval_acc': 0.5125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-26-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*net*mask*mask*：*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:28:29.166566', 'iflytek_dev_eval_loss': 2.659247398376465, 'iflytek_dev_eval_acc': 0.4028985507246377, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-24-55_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:29:17.773307', 'tnews_dev_eval_loss': 2.1404216289520264, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-27-50_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:31:02.494515', 'tnews_dev_eval_loss': 1.9031959772109985, 'tnews_dev_eval_acc': 0.5458333333333333, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-29-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*|*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:32:31.632086', 'iflytek_dev_eval_loss': 2.760551929473877, 'iflytek_dev_eval_acc': 0.39710144927536234, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-28-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:32:51.108499', 'tnews_dev_eval_loss': 2.1517443656921387, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-31-11_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:34:34.724520', 'tnews_dev_eval_loss': 2.7399706840515137, 'tnews_dev_eval_acc': 0.49583333333333335, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-32-57_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:36:23.673394', 'tnews_dev_eval_loss': 2.0672693252563477, 'tnews_dev_eval_acc': 0.5166666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-34-42_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*新*mask*mask*:*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:36:33.840323', 'iflytek_dev_eval_loss': 2.786757707595825, 'iflytek_dev_eval_acc': 0.3927536231884058, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-32-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:37:49.890345', 'tnews_dev_eval_loss': 2.268777370452881, 'tnews_dev_eval_acc': 0.5291666666666667, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-36-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-3571', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:39:42.219220', 'iflytek_dev_eval_loss': 2.726134777069092, 'iflytek_dev_eval_acc': 0.4, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-36-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*与*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:42:22.370742', 'iflytek_dev_eval_loss': 2.91860294342041, 'iflytek_dev_eval_acc': 0.4028985507246377, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-39-58_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:45:05.765306', 'iflytek_dev_eval_loss': 2.668325901031494, 'iflytek_dev_eval_acc': 0.4101449275362319, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-42-38_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:47:48.248482', 'iflytek_dev_eval_loss': 2.658926010131836, 'iflytek_dev_eval_acc': 0.40869565217391307, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-45-22_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:50:32.061412', 'iflytek_dev_eval_loss': 2.6516799926757812, 'iflytek_dev_eval_acc': 0.39710144927536234, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-48-04_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在线*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:53:14.737589', 'iflytek_dev_eval_loss': 2.507448434829712, 'iflytek_dev_eval_acc': 0.4260869565217391, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-50-48_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:55:56.713065', 'iflytek_dev_eval_loss': 2.5297327041625977, 'iflytek_dev_eval_acc': 0.4246376811594203, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-53-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 03:58:38.367433', 'iflytek_dev_eval_loss': 2.5000572204589844, 'iflytek_dev_eval_acc': 0.43768115942028984, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-56-13_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:01:20.225941', 'iflytek_dev_eval_loss': 2.6212825775146484, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_03-58-54_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:04:02.818088', 'iflytek_dev_eval_loss': 2.628054618835449, 'iflytek_dev_eval_acc': 0.40869565217391307, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-01-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:06:45.212093', 'iflytek_dev_eval_loss': 2.500195026397705, 'iflytek_dev_eval_acc': 0.43623188405797103, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-04-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:09:27.816599', 'iflytek_dev_eval_loss': 2.4647631645202637, 'iflytek_dev_eval_acc': 0.4405797101449275, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-07-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*。*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:12:08.566371', 'iflytek_dev_eval_loss': 2.824801445007324, 'iflytek_dev_eval_acc': 0.41594202898550725, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-09-44_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*爱*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:14:50.602385', 'iflytek_dev_eval_loss': 2.6369400024414062, 'iflytek_dev_eval_acc': 0.4246376811594203, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-12-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*上*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:17:31.929511', 'iflytek_dev_eval_loss': 2.512878894805908, 'iflytek_dev_eval_acc': 0.43478260869565216, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-15-07_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:20:14.786711', 'iflytek_dev_eval_loss': 2.8084802627563477, 'iflytek_dev_eval_acc': 0.4101449275362319, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-17-48_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:22:57.325787', 'iflytek_dev_eval_loss': 2.5441882610321045, 'iflytek_dev_eval_acc': 0.41739130434782606, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-20-31_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*网*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:25:40.080946', 'iflytek_dev_eval_loss': 2.5985612869262695, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-23-13_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:28:22.837305', 'iflytek_dev_eval_loss': 2.4640190601348877, 'iflytek_dev_eval_acc': 0.4492753623188406, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-25-56_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*(*mask*mask*)*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:31:05.568765', 'iflytek_dev_eval_loss': 2.632310390472412, 'iflytek_dev_eval_acc': 0.43043478260869567, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-28-39_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-9827', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:33:47.262617', 'iflytek_dev_eval_loss': 2.831469774246216, 'iflytek_dev_eval_acc': 0.40869565217391307, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-31-21_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:36:29.589726', 'iflytek_dev_eval_loss': 2.7867395877838135, 'iflytek_dev_eval_acc': 0.41304347826086957, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-34-03_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:39:12.722880', 'iflytek_dev_eval_loss': 2.827446460723877, 'iflytek_dev_eval_acc': 0.4028985507246377, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-36-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:41:54.622603', 'iflytek_dev_eval_loss': 2.8426098823547363, 'iflytek_dev_eval_acc': 0.4101449275362319, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-39-29_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*app*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:44:36.123648', 'iflytek_dev_eval_loss': 2.819697141647339, 'iflytek_dev_eval_acc': 0.4028985507246377, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-42-11_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:47:20.070013', 'iflytek_dev_eval_loss': 2.783228874206543, 'iflytek_dev_eval_acc': 0.4101449275362319, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-44-52_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*微*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:50:03.314484', 'iflytek_dev_eval_loss': 2.8423924446105957, 'iflytek_dev_eval_acc': 0.39710144927536234, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-47-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:52:44.747423', 'iflytek_dev_eval_loss': 2.8321707248687744, 'iflytek_dev_eval_acc': 0.4072463768115942, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-50-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:55:27.469861', 'iflytek_dev_eval_loss': 2.764221668243408, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-53-01_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 04:58:09.358736', 'iflytek_dev_eval_loss': 2.820164680480957, 'iflytek_dev_eval_acc': 0.41304347826086957, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-55-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:00:51.817249', 'iflytek_dev_eval_loss': 2.7258975505828857, 'iflytek_dev_eval_acc': 0.41304347826086957, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_04-58-25_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*与*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:03:34.818539', 'iflytek_dev_eval_loss': 2.7895259857177734, 'iflytek_dev_eval_acc': 0.41304347826086957, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-01-08_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*的*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:06:17.646503', 'iflytek_dev_eval_loss': 2.6867246627807617, 'iflytek_dev_eval_acc': 0.41884057971014493, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-03-51_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:09:01.114917', 'iflytek_dev_eval_loss': 2.691812515258789, 'iflytek_dev_eval_acc': 0.41884057971014493, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-06-34_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*更多*mask*mask*！*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:11:44.015173', 'iflytek_dev_eval_loss': 2.7102227210998535, 'iflytek_dev_eval_acc': 0.4101449275362319, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-09-17_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在线*mask*mask*。*sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:14:26.663932', 'iflytek_dev_eval_loss': 2.6352643966674805, 'iflytek_dev_eval_acc': 0.4144927536231884, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-12-00_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*【*mask*mask*】*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:17:09.826476', 'iflytek_dev_eval_loss': 2.647700548171997, 'iflytek_dev_eval_acc': 0.42028985507246375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-14-43_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:19:52.826816', 'iflytek_dev_eval_loss': 2.614724636077881, 'iflytek_dev_eval_acc': 0.42028985507246375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-17-26_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*：*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:22:36.624351', 'iflytek_dev_eval_loss': 2.7490620613098145, 'iflytek_dev_eval_acc': 0.4043478260869565, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-20-09_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:25:19.957175', 'iflytek_dev_eval_loss': 2.732473611831665, 'iflytek_dev_eval_acc': 0.41884057971014493, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-22-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:28:02.149072', 'iflytek_dev_eval_loss': 2.5487139225006104, 'iflytek_dev_eval_acc': 0.4260869565217391, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-25-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*。*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:30:46.209255', 'iflytek_dev_eval_loss': 2.5928232669830322, 'iflytek_dev_eval_acc': 0.4318840579710145, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-28-18_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:33:28.704197', 'iflytek_dev_eval_loss': 2.655585765838623, 'iflytek_dev_eval_acc': 0.41304347826086957, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-31-02_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*爱*mask*mask*，*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:36:11.862605', 'iflytek_dev_eval_loss': 2.7474007606506348, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-33-45_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*上*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:38:54.228463', 'iflytek_dev_eval_loss': 2.6422274112701416, 'iflytek_dev_eval_acc': 0.4289855072463768, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-36-28_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*好*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:41:37.007314', 'iflytek_dev_eval_loss': 2.6529879570007324, 'iflytek_dev_eval_acc': 0.4260869565217391, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-39-10_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*网*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:44:20.007052', 'iflytek_dev_eval_loss': 2.595815896987915, 'iflytek_dev_eval_acc': 0.43623188405797103, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-41-53_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*(*mask*mask*)*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:47:03.108791', 'iflytek_dev_eval_loss': 2.69476056098938, 'iflytek_dev_eval_acc': 0.43623188405797103, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-44-36_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:49:46.835671', 'iflytek_dev_eval_loss': 2.8916189670562744, 'iflytek_dev_eval_acc': 0.3869565217391304, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-47-19_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-23 05:52:30.289446', 'iflytek_dev_eval_loss': 2.644314765930176, 'iflytek_dev_eval_acc': 0.4115942028985507, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul23_05-50-03_61126fdd3402', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-16298', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask**+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 22:59:23.217156', 'bustm_dev_eval_loss': 1.2706332206726074, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_22-58-30_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:00:42.969189', 'bustm_dev_eval_loss': 1.7119295597076416, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_22-59-27_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:00:49.468972', 'ocnli_dev_eval_loss': 3.6821484565734863, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_22-59-31_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:02:01.315695', 'bustm_dev_eval_loss': 2.4205281734466553, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-00-48_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:02:08.977534', 'ocnli_dev_eval_loss': 2.5608158111572266, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-00-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:03:20.118513', 'bustm_dev_eval_loss': 0.7945359349250793, 'bustm_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-02-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:03:28.693058', 'ocnli_dev_eval_loss': 2.90922474861145, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-02-14_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:04:38.287247', 'bustm_dev_eval_loss': 2.0462284088134766, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-03-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*你*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:04:47.261906', 'ocnli_dev_eval_loss': 2.802243232727051, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-03-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:05:55.986179', 'bustm_dev_eval_loss': 2.6975340843200684, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-04-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:06:03.992639', 'ocnli_dev_eval_loss': 2.7814431190490723, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-04-52_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:07:14.536882', 'bustm_dev_eval_loss': 0.7600196599960327, 'bustm_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-06-01_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:07:21.938754', 'ocnli_dev_eval_loss': 3.5885863304138184, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-06-09_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:08:33.650336', 'bustm_dev_eval_loss': 2.919633388519287, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-07-20_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:08:40.942783', 'ocnli_dev_eval_loss': 3.895673990249634, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-07-26_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:09:53.890839', 'bustm_dev_eval_loss': 3.040168046951294, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-08-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:10:00.857311', 'ocnli_dev_eval_loss': 3.6473195552825928, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-08-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:11:13.336312', 'bustm_dev_eval_loss': 1.376043677330017, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-09-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:11:19.795296', 'ocnli_dev_eval_loss': 3.5526187419891357, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-10-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:12:31.064077', 'bustm_dev_eval_loss': 2.305407762527466, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-11-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*啊*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:12:39.104540', 'ocnli_dev_eval_loss': 2.671369791030884, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-11-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:13:48.881776', 'bustm_dev_eval_loss': 2.563072919845581, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-12-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:13:57.633310', 'ocnli_dev_eval_loss': 3.5875866413116455, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-12-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:15:06.471371', 'bustm_dev_eval_loss': 1.447296380996704, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-13-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:15:14.293736', 'ocnli_dev_eval_loss': 3.2883715629577637, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-14-02_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:16:23.184569', 'bustm_dev_eval_loss': 1.6044862270355225, 'bustm_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-15-11_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:16:32.796390', 'ocnli_dev_eval_loss': 3.7813117504119873, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-15-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:17:40.652678', 'bustm_dev_eval_loss': 3.714123249053955, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-16-28_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*看*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:17:50.036912', 'ocnli_dev_eval_loss': 3.339292287826538, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-16-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:19:02.097568', 'bustm_dev_eval_loss': 2.3028130531311035, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-17-46_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:19:08.684217', 'ocnli_dev_eval_loss': 3.227618455886841, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-17-55_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:20:20.248142', 'bustm_dev_eval_loss': 2.2349579334259033, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-19-07_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:20:28.058970', 'ocnli_dev_eval_loss': 3.825706958770752, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-19-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:21:42.554406', 'bustm_dev_eval_loss': 3.0610198974609375, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-20-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*呢*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:21:49.244994', 'ocnli_dev_eval_loss': 2.1671736240386963, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-20-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:22:59.785159', 'bustm_dev_eval_loss': 1.9639811515808105, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-21-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:23:07.915668', 'ocnli_dev_eval_loss': 2.9540724754333496, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-21-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*.*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:24:20.870674', 'bustm_dev_eval_loss': 1.9742493629455566, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-23-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:24:27.393449', 'ocnli_dev_eval_loss': 2.6360599994659424, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-23-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:25:41.228386', 'bustm_dev_eval_loss': 2.525376796722412, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-24-26_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:25:47.358095', 'ocnli_dev_eval_loss': 4.100375175476074, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-24-32_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:26:59.689861', 'bustm_dev_eval_loss': 3.138759136199951, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-25-46_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*看*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:27:06.776870', 'ocnli_dev_eval_loss': 3.734718084335327, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-25-52_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*.*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:28:17.482084', 'bustm_dev_eval_loss': 1.8700964450836182, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-27-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:28:24.989202', 'ocnli_dev_eval_loss': 3.593754768371582, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-27-11_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*要*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:29:35.336426', 'bustm_dev_eval_loss': 2.940028190612793, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-28-22_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:29:42.872152', 'ocnli_dev_eval_loss': 2.800020456314087, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-28-30_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*,*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:30:53.429608', 'bustm_dev_eval_loss': 1.820534348487854, 'bustm_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-29-40_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:31:00.889026', 'ocnli_dev_eval_loss': 3.1620774269104004, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-29-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*这*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:32:15.225030', 'bustm_dev_eval_loss': 2.9905200004577637, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-30-58_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:32:21.219751', 'ocnli_dev_eval_loss': 2.622328042984009, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-31-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*过*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:33:34.167015', 'bustm_dev_eval_loss': 2.415191411972046, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-32-20_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*要*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:33:42.139083', 'ocnli_dev_eval_loss': 2.368407726287842, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-32-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*要*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:34:53.499930', 'bustm_dev_eval_loss': 2.797011375427246, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-33-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:35:01.852537', 'ocnli_dev_eval_loss': 3.0678675174713135, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-33-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:36:12.618426', 'bustm_dev_eval_loss': 2.5283985137939453, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-34-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:36:20.416576', 'ocnli_dev_eval_loss': 2.808342456817627, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-35-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*过*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:37:32.070470', 'bustm_dev_eval_loss': 2.3512117862701416, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-36-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21323', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:37:40.235304', 'ocnli_dev_eval_loss': 2.266071319580078, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-36-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*对*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:38:53.341867', 'bustm_dev_eval_loss': 1.3297683000564575, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-37-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:39:00.354623', 'ocnli_dev_eval_loss': 2.342001438140869, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-37-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-29087', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/1/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:40:13.460024', 'bustm_dev_eval_loss': 1.263331651687622, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-38-58_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:40:20.324757', 'ocnli_dev_eval_loss': 2.7834503650665283, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-39-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:41:34.761201', 'bustm_dev_eval_loss': 1.3286423683166504, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-40-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:41:41.159768', 'ocnli_dev_eval_loss': 2.984583854675293, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-40-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:42:52.355651', 'bustm_dev_eval_loss': 1.0707361698150635, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-41-40_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:43:00.070993', 'ocnli_dev_eval_loss': 3.201582431793213, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-41-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:44:10.924493', 'bustm_dev_eval_loss': 1.6042344570159912, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-42-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:44:17.980361', 'ocnli_dev_eval_loss': 2.9304800033569336, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-43-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:45:30.534086', 'bustm_dev_eval_loss': 1.3712064027786255, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-44-16_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:45:36.974226', 'ocnli_dev_eval_loss': 3.232487201690674, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-44-22_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:46:49.608548', 'bustm_dev_eval_loss': 2.313577651977539, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-45-35_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*的*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:46:56.571394', 'ocnli_dev_eval_loss': 2.2974853515625, 'ocnli_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-45-41_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*者*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:48:07.553311', 'bustm_dev_eval_loss': 1.719001054763794, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-46-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:48:14.903472', 'ocnli_dev_eval_loss': 3.001891613006592, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-47-01_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:49:26.982896', 'bustm_dev_eval_loss': 1.3550053834915161, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-48-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*啊*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:49:34.000492', 'ocnli_dev_eval_loss': 2.3261427879333496, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-48-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*者*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:50:46.630316', 'bustm_dev_eval_loss': 1.4601035118103027, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-49-32_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:50:53.810569', 'ocnli_dev_eval_loss': 3.421685218811035, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-49-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:52:05.779719', 'bustm_dev_eval_loss': 1.320219874382019, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-50-52_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:52:14.528207', 'ocnli_dev_eval_loss': 3.292724847793579, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-50-58_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:53:23.470512', 'bustm_dev_eval_loss': 1.1904468536376953, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-52-11_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:53:33.463636', 'ocnli_dev_eval_loss': 2.9455697536468506, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-52-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:54:41.236347', 'bustm_dev_eval_loss': 1.6867022514343262, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-53-29_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*你*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:54:50.059911', 'ocnli_dev_eval_loss': 3.0293760299682617, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-53-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:56:00.104751', 'bustm_dev_eval_loss': 1.337377667427063, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-54-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*看*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:56:07.527551', 'ocnli_dev_eval_loss': 3.4557178020477295, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-54-55_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:57:19.072040', 'bustm_dev_eval_loss': 1.0633094310760498, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-56-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:57:26.867758', 'ocnli_dev_eval_loss': 3.088223695755005, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-56-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:58:38.045704', 'bustm_dev_eval_loss': 1.4625941514968872, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-57-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*呢*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:58:45.776796', 'ocnli_dev_eval_loss': 3.029334545135498, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-57-32_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-25 23:59:57.008315', 'bustm_dev_eval_loss': 2.1841225624084473, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-58-43_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:00:03.858576', 'ocnli_dev_eval_loss': 4.087031364440918, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul25_23-58-50_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:01:14.361572', 'bustm_dev_eval_loss': 1.3256288766860962, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-00-02_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:01:22.245767', 'ocnli_dev_eval_loss': 2.751376152038574, 'ocnli_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-00-08_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:02:35.102732', 'bustm_dev_eval_loss': 1.6943000555038452, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-01-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:02:41.593211', 'ocnli_dev_eval_loss': 3.1388211250305176, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-01-27_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*的*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:03:53.659954', 'bustm_dev_eval_loss': 1.5245845317840576, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-02-40_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:04:00.444845', 'ocnli_dev_eval_loss': 3.1926822662353516, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-02-46_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:05:12.827174', 'bustm_dev_eval_loss': 1.7471609115600586, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-03-58_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:05:19.353831', 'ocnli_dev_eval_loss': 2.8333072662353516, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-04-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*了*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:06:31.425129', 'bustm_dev_eval_loss': 1.934044361114502, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-05-17_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:06:39.207143', 'ocnli_dev_eval_loss': 2.9825730323791504, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-05-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*为*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:07:52.054021', 'bustm_dev_eval_loss': 1.9857439994812012, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-06-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*好*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:07:58.540566', 'ocnli_dev_eval_loss': 2.8633828163146973, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-06-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:09:12.454313', 'bustm_dev_eval_loss': 2.95218563079834, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-07-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:09:18.201951', 'ocnli_dev_eval_loss': 2.3783507347106934, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-08-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:10:33.583173', 'bustm_dev_eval_loss': 1.8191924095153809, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-09-17_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*和*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:10:39.286274', 'ocnli_dev_eval_loss': 2.6585912704467773, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-09-23_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*为*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:11:54.790716', 'bustm_dev_eval_loss': 1.7426300048828125, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-10-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*能*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:12:00.379124', 'ocnli_dev_eval_loss': 2.9624459743499756, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-10-43_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*.*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:13:13.538422', 'bustm_dev_eval_loss': 1.7292375564575195, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-11-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*要*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:13:20.158162', 'ocnli_dev_eval_loss': 1.9186766147613525, 'ocnli_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-12-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*过*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:14:33.931531', 'bustm_dev_eval_loss': 2.476799488067627, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-13-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*真*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:14:40.547390', 'ocnli_dev_eval_loss': 3.759779214859009, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-13-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:15:54.149051', 'bustm_dev_eval_loss': 1.8672068119049072, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-14-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:16:00.437459', 'ocnli_dev_eval_loss': 2.195176839828491, 'ocnli_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-14-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*过*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:17:12.934343', 'bustm_dev_eval_loss': 1.3819530010223389, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-15-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-27936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:17:19.863407', 'ocnli_dev_eval_loss': 2.4304323196411133, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-16-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:18:32.521383', 'bustm_dev_eval_loss': 1.9827312231063843, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-17-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:18:39.116632', 'ocnli_dev_eval_loss': 2.353604793548584, 'ocnli_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-17-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-5743', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/2/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:19:50.792127', 'bustm_dev_eval_loss': 1.9375059604644775, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-18-37_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:19:58.549105', 'ocnli_dev_eval_loss': 3.1410884857177734, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-18-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:21:06.931134', 'bustm_dev_eval_loss': 1.6517633199691772, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-19-56_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:21:15.898089', 'ocnli_dev_eval_loss': 3.647960901260376, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-20-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:22:26.655504', 'bustm_dev_eval_loss': 2.170576572418213, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-21-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:22:33.845247', 'ocnli_dev_eval_loss': 3.1870250701904297, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-21-20_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:23:45.559965', 'bustm_dev_eval_loss': 1.9987564086914062, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-22-32_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:23:53.227890', 'ocnli_dev_eval_loss': 3.8728833198547363, 'ocnli_dev_eval_acc': 0.21875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-22-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:25:03.691978', 'bustm_dev_eval_loss': 2.3450233936309814, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-23-51_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:25:11.499737', 'ocnli_dev_eval_loss': 2.331125497817993, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-23-58_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:26:22.525820', 'bustm_dev_eval_loss': 1.6482009887695312, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-25-09_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*啊*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:26:30.095555', 'ocnli_dev_eval_loss': 3.2633211612701416, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-25-16_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:27:41.721878', 'bustm_dev_eval_loss': 3.949944496154785, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-26-28_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:27:49.116147', 'ocnli_dev_eval_loss': 3.587416172027588, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-26-35_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:29:02.718225', 'bustm_dev_eval_loss': 2.2831108570098877, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-27-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:29:08.835083', 'ocnli_dev_eval_loss': 2.975775718688965, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-27-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:30:22.231038', 'bustm_dev_eval_loss': 2.385359764099121, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-29-07_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:30:29.170448', 'ocnli_dev_eval_loss': 1.9808862209320068, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-29-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:31:42.198810', 'bustm_dev_eval_loss': 1.7199344635009766, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-30-27_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:31:48.730689', 'ocnli_dev_eval_loss': 3.225531578063965, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-30-34_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:32:59.848319', 'bustm_dev_eval_loss': 2.04551100730896, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-31-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:33:07.494743', 'ocnli_dev_eval_loss': 2.6936917304992676, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-31-53_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:34:16.067221', 'bustm_dev_eval_loss': 3.7107443809509277, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-33-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:34:25.142047', 'ocnli_dev_eval_loss': 3.2522406578063965, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-33-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:35:32.806618', 'bustm_dev_eval_loss': 2.3725290298461914, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-34-21_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:35:41.367966', 'ocnli_dev_eval_loss': 2.601972818374634, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-34-30_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:36:52.441633', 'bustm_dev_eval_loss': 3.621476650238037, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-35-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:36:59.283775', 'ocnli_dev_eval_loss': 3.525237798690796, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-35-46_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:38:10.164431', 'bustm_dev_eval_loss': 2.475914716720581, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-36-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*你*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:38:17.439020', 'ocnli_dev_eval_loss': 3.1262731552124023, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-37-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:39:28.267522', 'bustm_dev_eval_loss': 3.7285561561584473, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-38-15_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*看*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:39:35.479903', 'ocnli_dev_eval_loss': 4.189302921295166, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-38-22_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:40:48.866261', 'bustm_dev_eval_loss': 2.815246343612671, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-39-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:40:55.227925', 'ocnli_dev_eval_loss': 3.231348991394043, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-39-40_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:42:06.865167', 'bustm_dev_eval_loss': 2.88687801361084, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-40-53_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:42:13.906949', 'ocnli_dev_eval_loss': 3.9145760536193848, 'ocnli_dev_eval_acc': 0.25, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-40-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:43:25.045432', 'bustm_dev_eval_loss': 1.8339275121688843, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-42-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*呢*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:43:33.942446', 'ocnli_dev_eval_loss': 3.009279251098633, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-42-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:44:46.913709', 'bustm_dev_eval_loss': 3.3309102058410645, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-43-31_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:44:55.385886', 'ocnli_dev_eval_loss': 3.0475752353668213, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-43-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:46:07.041587', 'bustm_dev_eval_loss': 2.4344615936279297, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-44-52_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:46:15.251211', 'ocnli_dev_eval_loss': 3.9472219944000244, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-45-00_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:47:30.425859', 'bustm_dev_eval_loss': 2.3793272972106934, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-46-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*我*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:47:37.501076', 'ocnli_dev_eval_loss': 2.9265642166137695, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-46-21_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:48:51.333780', 'bustm_dev_eval_loss': 2.018247604370117, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-47-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:48:58.470799', 'ocnli_dev_eval_loss': 1.9396860599517822, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-47-43_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:50:10.610539', 'bustm_dev_eval_loss': 1.8181006908416748, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-48-56_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:50:21.118857', 'ocnli_dev_eval_loss': 3.1264829635620117, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-49-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:51:32.499317', 'bustm_dev_eval_loss': 2.3496856689453125, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-50-17_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:51:40.161709', 'ocnli_dev_eval_loss': 3.9147229194641113, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-50-26_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*许*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:52:54.587396', 'bustm_dev_eval_loss': 2.0608267784118652, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-51-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:53:01.310874', 'ocnli_dev_eval_loss': 3.5385959148406982, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-51-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*错*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:54:14.009109', 'bustm_dev_eval_loss': 2.2120189666748047, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-53-00_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*要*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:54:21.580866', 'ocnli_dev_eval_loss': 2.265925168991089, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-53-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:55:34.853225', 'bustm_dev_eval_loss': 2.7028424739837646, 'bustm_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-54-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:55:42.586844', 'ocnli_dev_eval_loss': 2.6150543689727783, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-54-26_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:56:57.695368', 'bustm_dev_eval_loss': 2.5867135524749756, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-55-40_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-24975', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:57:04.610644', 'ocnli_dev_eval_loss': 3.8461689949035645, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-55-48_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:58:19.340583', 'bustm_dev_eval_loss': 2.0220906734466553, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-57-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:58:26.395215', 'ocnli_dev_eval_loss': 3.0966074466705322, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-57-09_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4197', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*过*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/3/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:59:40.141895', 'bustm_dev_eval_loss': 2.176720142364502, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-58-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 00:59:48.044705', 'ocnli_dev_eval_loss': 2.587679386138916, 'ocnli_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-58-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:01:01.070404', 'bustm_dev_eval_loss': 1.1729726791381836, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-59-46_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:01:08.276056', 'ocnli_dev_eval_loss': 3.7513065338134766, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_00-59-53_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:02:24.658801', 'bustm_dev_eval_loss': 1.5873947143554688, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-01-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:02:30.605619', 'ocnli_dev_eval_loss': 3.2130401134490967, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-01-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:03:47.905722', 'bustm_dev_eval_loss': 1.4935619831085205, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-02-30_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:03:53.197692', 'ocnli_dev_eval_loss': 2.0813465118408203, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-02-35_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:05:10.725886', 'bustm_dev_eval_loss': 2.4250245094299316, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-03-53_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:05:16.258271', 'ocnli_dev_eval_loss': 2.605375289916992, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-03-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:06:33.404571', 'bustm_dev_eval_loss': 1.1301347017288208, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-05-16_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:06:39.102189', 'ocnli_dev_eval_loss': 2.4703266620635986, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-05-20_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:07:55.935931', 'bustm_dev_eval_loss': 2.0098838806152344, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-06-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:08:02.293800', 'ocnli_dev_eval_loss': 3.1483287811279297, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-06-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:09:15.697303', 'bustm_dev_eval_loss': 1.951639175415039, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-08-01_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:09:23.575511', 'ocnli_dev_eval_loss': 2.53334903717041, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-08-07_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:10:36.667572', 'bustm_dev_eval_loss': 1.7899383306503296, 'bustm_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-09-21_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*啊*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:10:44.710448', 'ocnli_dev_eval_loss': 2.005002737045288, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-09-29_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:11:57.845506', 'bustm_dev_eval_loss': 1.7246387004852295, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-10-42_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*？*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:12:05.292687', 'ocnli_dev_eval_loss': 3.5072402954101562, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-10-49_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:13:17.510532', 'bustm_dev_eval_loss': 1.2943722009658813, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-12-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:13:25.579656', 'ocnli_dev_eval_loss': 1.9294493198394775, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-12-10_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*的*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:14:39.113002', 'bustm_dev_eval_loss': 2.4714369773864746, 'bustm_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-13-23_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:14:46.358788', 'ocnli_dev_eval_loss': 3.153264284133911, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-13-31_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:15:59.820656', 'bustm_dev_eval_loss': 2.1971893310546875, 'bustm_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-14-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:16:06.967450', 'ocnli_dev_eval_loss': 3.678400993347168, 'ocnli_dev_eval_acc': 0.21875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-14-51_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:17:20.626745', 'bustm_dev_eval_loss': 1.2176015377044678, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-16-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*的*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:17:28.730889', 'ocnli_dev_eval_loss': 2.744398355484009, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-16-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:18:39.871086', 'bustm_dev_eval_loss': 2.8594982624053955, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-17-26_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:18:47.045032', 'ocnli_dev_eval_loss': 2.2228047847747803, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-17-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:19:56.977469', 'bustm_dev_eval_loss': 1.997910737991333, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-18-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*呢*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:20:07.306059', 'ocnli_dev_eval_loss': 2.727806806564331, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-18-52_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:21:13.692899', 'bustm_dev_eval_loss': 2.9900400638580322, 'bustm_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-20-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:21:23.902218', 'ocnli_dev_eval_loss': 2.3105273246765137, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-20-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:22:30.700289', 'bustm_dev_eval_loss': 1.892474889755249, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-21-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*你*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:22:43.196445', 'ocnli_dev_eval_loss': 3.4117305278778076, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-21-29_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*我*mask*说*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:23:49.184321', 'bustm_dev_eval_loss': 3.8033151626586914, 'bustm_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-22-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:24:02.847384', 'ocnli_dev_eval_loss': 2.7535557746887207, 'ocnli_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-22-49_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:25:05.082607', 'bustm_dev_eval_loss': 1.3561598062515259, 'bustm_dev_eval_acc': 0.6875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-23-55_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*说*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:25:19.186715', 'ocnli_dev_eval_loss': 2.124789237976074, 'ocnli_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-24-08_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*也*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:26:19.855186', 'bustm_dev_eval_loss': 1.061875343322754, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-25-10_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*了*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:26:35.383459', 'ocnli_dev_eval_loss': 2.4875497817993164, 'ocnli_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-25-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:27:35.335159', 'bustm_dev_eval_loss': 3.200817584991455, 'bustm_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-26-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:27:50.890816', 'ocnli_dev_eval_loss': 2.6825385093688965, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-26-41_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*了*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:28:51.021426', 'bustm_dev_eval_loss': 1.723231315612793, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-27-41_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*我*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:29:06.326427', 'ocnli_dev_eval_loss': 3.217958927154541, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-27-56_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:30:09.435718', 'bustm_dev_eval_loss': 2.4634153842926025, 'bustm_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-28-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:30:21.424124', 'ocnli_dev_eval_loss': 2.783752202987671, 'ocnli_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-29-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*这*mask*是*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:31:26.950690', 'bustm_dev_eval_loss': 2.1859920024871826, 'bustm_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-30-15_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*不*mask*认*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:31:38.727537', 'ocnli_dev_eval_loss': 2.8971028327941895, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-30-27_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*让*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:32:44.734372', 'bustm_dev_eval_loss': 3.075688362121582, 'bustm_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-31-32_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*要*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:32:54.796917', 'ocnli_dev_eval_loss': 1.8725067377090454, 'ocnli_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-31-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:34:01.956522', 'bustm_dev_eval_loss': 3.5169801712036133, 'bustm_dev_eval_acc': 0.375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-32-50_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:34:12.030782', 'ocnli_dev_eval_loss': 2.8921327590942383, 'ocnli_dev_eval_acc': 0.3125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-33-00_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*过*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:35:19.738976', 'bustm_dev_eval_loss': 2.7611870765686035, 'bustm_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-34-07_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*定*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:35:28.658585', 'ocnli_dev_eval_loss': 2.641347885131836, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-34-17_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:36:38.889038', 'bustm_dev_eval_loss': 2.287381649017334, 'bustm_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-35-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7935', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:36:45.453628', 'ocnli_dev_eval_loss': 2.3996410369873047, 'ocnli_dev_eval_acc': 0.34375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-35-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*只*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:37:33.334243', 'ocnli_dev_eval_loss': 3.174961566925049, 'ocnli_dev_eval_acc': 0.28125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-36-49_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-24036', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*还*mask*在*+sentl_1**sep+*', 'mapping': '{"contradiction": "不", "neutral": "或", "entailment": "是"}', 'template_path': 'my_auto_template/4/ocnli/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:45:18.607062', 'csldcp_dev_eval_loss': 2.1149637699127197, 'csldcp_dev_eval_acc': 0.4608208955223881, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-43-08_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:47:39.918289', 'csldcp_dev_eval_loss': 2.14277982711792, 'csldcp_dev_eval_acc': 0.45149253731343286, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-45-32_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:50:00.625293', 'csldcp_dev_eval_loss': 2.0511181354522705, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-47-53_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:52:21.597205', 'csldcp_dev_eval_loss': 2.056023359298706, 'csldcp_dev_eval_acc': 0.46828358208955223, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-50-14_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:54:42.530461', 'csldcp_dev_eval_loss': 2.0681662559509277, 'csldcp_dev_eval_acc': 0.46828358208955223, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-52-35_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*：*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:57:03.262347', 'csldcp_dev_eval_loss': 2.13688325881958, 'csldcp_dev_eval_acc': 0.46828358208955223, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-54-56_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 01:59:24.286577', 'csldcp_dev_eval_loss': 2.047701358795166, 'csldcp_dev_eval_acc': 0.458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-57-16_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*[*mask*mask*]*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:01:45.406393', 'csldcp_dev_eval_loss': 2.0083422660827637, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_01-59-37_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*到*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:04:06.103317', 'csldcp_dev_eval_loss': 2.1983537673950195, 'csldcp_dev_eval_acc': 0.43843283582089554, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-01-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:06:26.734936', 'csldcp_dev_eval_loss': 2.0726616382598877, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-04-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:08:46.889986', 'csldcp_dev_eval_loss': 2.0287399291992188, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-06-40_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*中*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:11:05.767679', 'csldcp_dev_eval_loss': 2.103161096572876, 'csldcp_dev_eval_acc': 0.44402985074626866, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-08-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:13:25.489951', 'csldcp_dev_eval_loss': 2.009183168411255, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-11-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:15:44.876415', 'csldcp_dev_eval_loss': 2.011807680130005, 'csldcp_dev_eval_acc': 0.46828358208955223, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-13-38_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*上*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:18:04.249837', 'csldcp_dev_eval_loss': 2.0357327461242676, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-15-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*界*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:20:23.829490', 'csldcp_dev_eval_loss': 2.288402557373047, 'csldcp_dev_eval_acc': 0.44402985074626866, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-18-17_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:22:43.610532', 'csldcp_dev_eval_loss': 2.2383718490600586, 'csldcp_dev_eval_acc': 0.44776119402985076, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-20-37_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*上*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:25:02.898620', 'csldcp_dev_eval_loss': 2.343315601348877, 'csldcp_dev_eval_acc': 0.4216417910447761, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-22-56_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*，*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:27:22.875963', 'csldcp_dev_eval_loss': 2.017347574234009, 'csldcp_dev_eval_acc': 0.4869402985074627, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-25-16_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*学*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:29:42.659016', 'csldcp_dev_eval_loss': 2.0995712280273438, 'csldcp_dev_eval_acc': 0.47947761194029853, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-27-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*史*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:32:01.843816', 'csldcp_dev_eval_loss': 2.019327402114868, 'csldcp_dev_eval_acc': 0.4906716417910448, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-29-55_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*网*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:34:21.608184', 'csldcp_dev_eval_loss': 2.0045456886291504, 'csldcp_dev_eval_acc': 0.47947761194029853, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-32-14_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*。*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:36:41.247090', 'csldcp_dev_eval_loss': 2.12272047996521, 'csldcp_dev_eval_acc': 0.47947761194029853, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-34-34_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*界*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:39:00.739518', 'csldcp_dev_eval_loss': 2.10119891166687, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-36-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*会*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:41:21.295923', 'csldcp_dev_eval_loss': 2.161440372467041, 'csldcp_dev_eval_acc': 0.4552238805970149, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-39-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*的*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:43:41.326110', 'csldcp_dev_eval_loss': 2.123835325241089, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-41-34_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*，*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:46:00.570750', 'csldcp_dev_eval_loss': 2.031560182571411, 'csldcp_dev_eval_acc': 0.48134328358208955, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-43-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*：*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:48:21.045816', 'csldcp_dev_eval_loss': 2.121001720428467, 'csldcp_dev_eval_acc': 0.4832089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-46-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*系*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:50:41.334967', 'csldcp_dev_eval_loss': 2.092724323272705, 'csldcp_dev_eval_acc': 0.47761194029850745, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-48-34_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*部*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:53:01.257435', 'csldcp_dev_eval_loss': 2.1089909076690674, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-50-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18910', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*家*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:55:21.538627', 'csldcp_dev_eval_loss': 2.0955569744110107, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-53-15_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 02:57:41.528904', 'csldcp_dev_eval_loss': 2.1341605186462402, 'csldcp_dev_eval_acc': 0.458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-55-34_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:00:00.812182', 'csldcp_dev_eval_loss': 2.136634588241577, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_02-57-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:02:18.631101', 'csldcp_dev_eval_loss': 2.2410099506378174, 'csldcp_dev_eval_acc': 0.4608208955223881, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-00-13_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:04:38.209056', 'csldcp_dev_eval_loss': 2.159210205078125, 'csldcp_dev_eval_acc': 0.4608208955223881, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-02-31_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*：*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:06:57.529795', 'csldcp_dev_eval_loss': 2.1495954990386963, 'csldcp_dev_eval_acc': 0.45149253731343286, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-04-51_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:09:17.064310', 'csldcp_dev_eval_loss': 2.1541073322296143, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-07-10_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*[*mask*mask*]*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:11:36.905149', 'csldcp_dev_eval_loss': 2.0975000858306885, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-09-30_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*到*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:13:57.197170', 'csldcp_dev_eval_loss': 2.2252442836761475, 'csldcp_dev_eval_acc': 0.458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-11-50_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:16:15.152638', 'csldcp_dev_eval_loss': 2.4800949096679688, 'csldcp_dev_eval_acc': 0.4552238805970149, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-14-10_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:18:35.123231', 'csldcp_dev_eval_loss': 2.307790756225586, 'csldcp_dev_eval_acc': 0.47201492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-16-28_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*中*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:20:53.675784', 'csldcp_dev_eval_loss': 2.3999733924865723, 'csldcp_dev_eval_acc': 0.45149253731343286, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-18-48_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:23:14.037275', 'csldcp_dev_eval_loss': 2.0492773056030273, 'csldcp_dev_eval_acc': 0.4869402985074627, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-21-07_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:25:33.394929', 'csldcp_dev_eval_loss': 2.3233542442321777, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-23-27_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*上*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:27:52.188112', 'csldcp_dev_eval_loss': 2.3307852745056152, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-25-46_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*界*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:30:12.495533', 'csldcp_dev_eval_loss': 2.142362117767334, 'csldcp_dev_eval_acc': 0.4552238805970149, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-28-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:32:33.898720', 'csldcp_dev_eval_loss': 2.11948823928833, 'csldcp_dev_eval_acc': 0.4626865671641791, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-30-26_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*学*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:34:55.258129', 'csldcp_dev_eval_loss': 2.1007113456726074, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-32-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*网*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:37:15.947275', 'csldcp_dev_eval_loss': 2.221308946609497, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-35-08_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*史*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:39:37.443254', 'csldcp_dev_eval_loss': 2.0814239978790283, 'csldcp_dev_eval_acc': 0.48134328358208955, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-37-29_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*。*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:41:58.968620', 'csldcp_dev_eval_loss': 2.242176055908203, 'csldcp_dev_eval_acc': 0.4701492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-39-51_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*会*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:44:19.834538', 'csldcp_dev_eval_loss': 2.235828399658203, 'csldcp_dev_eval_acc': 0.44216417910447764, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-42-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*界*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:46:41.362513', 'csldcp_dev_eval_loss': 2.0925145149230957, 'csldcp_dev_eval_acc': 0.4701492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-44-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*：*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:49:01.507723', 'csldcp_dev_eval_loss': 2.184842348098755, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-46-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*系*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:51:22.445246', 'csldcp_dev_eval_loss': 2.1095261573791504, 'csldcp_dev_eval_acc': 0.4608208955223881, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-49-14_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*，*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:53:43.428044', 'csldcp_dev_eval_loss': 2.1639299392700195, 'csldcp_dev_eval_acc': 0.44402985074626866, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-51-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*的*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:56:04.170955', 'csldcp_dev_eval_loss': 2.1175527572631836, 'csldcp_dev_eval_acc': 0.4701492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-53-56_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*部*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 03:58:26.075707', 'csldcp_dev_eval_loss': 2.176257371902466, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-56-17_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*家*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:00:47.697985', 'csldcp_dev_eval_loss': 2.1419622898101807, 'csldcp_dev_eval_acc': 0.4626865671641791, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_03-58-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*工*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:03:08.553605', 'csldcp_dev_eval_loss': 2.128310441970825, 'csldcp_dev_eval_acc': 0.47201492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-01-01_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13141', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*是*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:05:33.654650', 'csldcp_dev_eval_loss': 2.045135974884033, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-03-22_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:07:55.282676', 'csldcp_dev_eval_loss': 1.998008131980896, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-05-47_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:10:15.749427', 'csldcp_dev_eval_loss': 1.9645665884017944, 'csldcp_dev_eval_acc': 0.4626865671641791, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-08-08_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:12:36.941320', 'csldcp_dev_eval_loss': 2.010063409805298, 'csldcp_dev_eval_acc': 0.4626865671641791, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-10-29_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:14:57.841797', 'csldcp_dev_eval_loss': 2.0197765827178955, 'csldcp_dev_eval_acc': 0.4608208955223881, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-12-50_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*：*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:17:18.306770', 'csldcp_dev_eval_loss': 2.0617315769195557, 'csldcp_dev_eval_acc': 0.43843283582089554, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-15-11_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:19:39.223743', 'csldcp_dev_eval_loss': 1.9956309795379639, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-17-31_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*[*mask*mask*]*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:21:59.505124', 'csldcp_dev_eval_loss': 2.062478542327881, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-19-52_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:24:19.828940', 'csldcp_dev_eval_loss': 1.9977407455444336, 'csldcp_dev_eval_acc': 0.4626865671641791, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-22-12_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*到*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:26:40.816920', 'csldcp_dev_eval_loss': 2.0368874073028564, 'csldcp_dev_eval_acc': 0.4608208955223881, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-24-33_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:29:01.439217', 'csldcp_dev_eval_loss': 2.00447154045105, 'csldcp_dev_eval_acc': 0.4701492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-26-54_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:31:22.713891', 'csldcp_dev_eval_loss': 1.9753975868225098, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-29-15_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*中*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:33:44.309367', 'csldcp_dev_eval_loss': 1.9603126049041748, 'csldcp_dev_eval_acc': 0.4701492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-31-36_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:36:05.081569', 'csldcp_dev_eval_loss': 1.9945389032363892, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-33-57_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*上*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:38:26.230982', 'csldcp_dev_eval_loss': 1.9771788120269775, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-36-18_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*界*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:40:47.562796', 'csldcp_dev_eval_loss': 2.0988361835479736, 'csldcp_dev_eval_acc': 0.4533582089552239, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-38-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:43:08.249060', 'csldcp_dev_eval_loss': 2.0725252628326416, 'csldcp_dev_eval_acc': 0.4458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-41-00_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*学*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:45:29.669176', 'csldcp_dev_eval_loss': 2.0425949096679688, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-43-21_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*网*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:47:50.398516', 'csldcp_dev_eval_loss': 2.1011962890625, 'csldcp_dev_eval_acc': 0.44776119402985076, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-45-43_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*史*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:50:11.446101', 'csldcp_dev_eval_loss': 2.122912645339966, 'csldcp_dev_eval_acc': 0.4552238805970149, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-48-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*会*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:52:32.034248', 'csldcp_dev_eval_loss': 2.0815789699554443, 'csldcp_dev_eval_acc': 0.44776119402985076, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-50-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*界*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:54:51.705518', 'csldcp_dev_eval_loss': 1.9482731819152832, 'csldcp_dev_eval_acc': 0.46455223880597013, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-52-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*。*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:57:11.036273', 'csldcp_dev_eval_loss': 2.0410516262054443, 'csldcp_dev_eval_acc': 0.4552238805970149, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-55-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*系*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 04:59:31.370423', 'csldcp_dev_eval_loss': 1.979404091835022, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-57-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*，*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:01:51.410458', 'csldcp_dev_eval_loss': 2.043445587158203, 'csldcp_dev_eval_acc': 0.4533582089552239, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_04-59-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*的*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:04:10.698538', 'csldcp_dev_eval_loss': 2.011817693710327, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-02-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*：*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:06:30.674693', 'csldcp_dev_eval_loss': 2.0246338844299316, 'csldcp_dev_eval_acc': 0.46828358208955223, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-04-23_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*部*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:08:51.012702', 'csldcp_dev_eval_loss': 2.070793867111206, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-06-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*工*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:11:10.731216', 'csldcp_dev_eval_loss': 2.091968059539795, 'csldcp_dev_eval_acc': 0.43656716417910446, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-09-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*家*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:13:30.636923', 'csldcp_dev_eval_loss': 2.162454605102539, 'csldcp_dev_eval_acc': 0.44776119402985076, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-11-23_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-5904', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*是*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:15:53.029853', 'csldcp_dev_eval_loss': 2.161571502685547, 'csldcp_dev_eval_acc': 0.4496268656716418, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-13-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:18:12.497582', 'csldcp_dev_eval_loss': 2.1519296169281006, 'csldcp_dev_eval_acc': 0.4533582089552239, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-16-06_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:20:32.661118', 'csldcp_dev_eval_loss': 2.0603978633880615, 'csldcp_dev_eval_acc': 0.45149253731343286, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-18-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:22:52.811838', 'csldcp_dev_eval_loss': 2.083899736404419, 'csldcp_dev_eval_acc': 0.44402985074626866, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-20-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*为*mask*mask*。*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:25:12.577637', 'csldcp_dev_eval_loss': 2.075833797454834, 'csldcp_dev_eval_acc': 0.4664179104477612, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-23-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*：*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:27:32.630502', 'csldcp_dev_eval_loss': 2.1555607318878174, 'csldcp_dev_eval_acc': 0.44402985074626866, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-25-25_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*新*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:29:52.538465', 'csldcp_dev_eval_loss': 2.015056610107422, 'csldcp_dev_eval_acc': 0.44776119402985076, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-27-45_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*[*mask*mask*]*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:32:11.618743', 'csldcp_dev_eval_loss': 2.0231919288635254, 'csldcp_dev_eval_acc': 0.47761194029850745, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-30-05_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*到*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:34:31.052202', 'csldcp_dev_eval_loss': 2.1504106521606445, 'csldcp_dev_eval_acc': 0.43470149253731344, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-32-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*如*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:36:51.006260', 'csldcp_dev_eval_loss': 2.0867130756378174, 'csldcp_dev_eval_acc': 0.45149253731343286, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-34-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*从*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:39:11.181569', 'csldcp_dev_eval_loss': 2.041231870651245, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-37-04_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*中*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:41:31.057311', 'csldcp_dev_eval_loss': 2.0802907943725586, 'csldcp_dev_eval_acc': 0.4626865671641791, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-39-24_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*.*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:43:50.275621', 'csldcp_dev_eval_loss': 1.9917750358581543, 'csldcp_dev_eval_acc': 0.458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-41-44_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*《*mask*mask*》*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:46:09.650686', 'csldcp_dev_eval_loss': 2.059981107711792, 'csldcp_dev_eval_acc': 0.4533582089552239, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-44-03_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*上*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:48:29.861524', 'csldcp_dev_eval_loss': 2.092841863632202, 'csldcp_dev_eval_acc': 0.4458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-46-22_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*在*mask*mask*界*sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:50:49.725329', 'csldcp_dev_eval_loss': 2.1919190883636475, 'csldcp_dev_eval_acc': 0.45149253731343286, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-48-43_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*中*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:53:08.848774', 'csldcp_dev_eval_loss': 2.146132707595825, 'csldcp_dev_eval_acc': 0.43843283582089554, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-51-02_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*在*mask*mask*上*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:55:28.245935', 'csldcp_dev_eval_loss': 1.988364577293396, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-53-21_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*学*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 05:57:48.284097', 'csldcp_dev_eval_loss': 2.0312089920043945, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-55-41_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*网*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:00:07.770999', 'csldcp_dev_eval_loss': 2.0885260105133057, 'csldcp_dev_eval_acc': 0.4552238805970149, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_05-58-01_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*史*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:02:27.716013', 'csldcp_dev_eval_loss': 2.028965711593628, 'csldcp_dev_eval_acc': 0.458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-00-20_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*界*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:04:47.664434', 'csldcp_dev_eval_loss': 2.01621150970459, 'csldcp_dev_eval_acc': 0.47947761194029853, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-02-41_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*。*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:07:06.878186', 'csldcp_dev_eval_loss': 2.0445947647094727, 'csldcp_dev_eval_acc': 0.47574626865671643, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-05-00_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*会*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:09:26.528399', 'csldcp_dev_eval_loss': 2.132727861404419, 'csldcp_dev_eval_acc': 0.4458955223880597, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-07-20_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*的*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:11:46.706910', 'csldcp_dev_eval_loss': 2.0400798320770264, 'csldcp_dev_eval_acc': 0.47388059701492535, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-09-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*系*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:14:06.194503', 'csldcp_dev_eval_loss': 2.045626401901245, 'csldcp_dev_eval_acc': 0.48880597014925375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-12-00_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*，*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:16:25.901386', 'csldcp_dev_eval_loss': 1.9783562421798706, 'csldcp_dev_eval_acc': 0.4906716417910448, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-14-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*：*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:18:46.168078', 'csldcp_dev_eval_loss': 2.0919029712677, 'csldcp_dev_eval_acc': 0.4701492537313433, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-16-39_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*部*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:21:06.136802', 'csldcp_dev_eval_loss': 2.053894519805908, 'csldcp_dev_eval_acc': 0.457089552238806, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-18-59_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*家*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-26 06:23:27.533073', 'csldcp_dev_eval_loss': 2.0309317111968994, 'csldcp_dev_eval_acc': 0.47761194029850745, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul26_06-21-19_4520f246d7e9', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-20244', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*工*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 19:58:19.447537', 'cluewsc_dev_eval_loss': 2.250669240951538, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_19-57-03_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:00:10.172359', 'cluewsc_dev_eval_loss': 1.8664124011993408, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_19-58-23_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:01:21.793602', 'csl_dev_eval_loss': 2.860720157623291, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_19-58-56_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:02:18.867991', 'cluewsc_dev_eval_loss': 3.22663950920105, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-00-16_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:03:58.888692', 'csl_dev_eval_loss': 2.9095661640167236, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-01-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*因*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:04:24.737041', 'cluewsc_dev_eval_loss': 2.1306819915771484, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-02-25_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*还*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:06:34.055395', 'csl_dev_eval_loss': 3.2948496341705322, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-04-05_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*能*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:06:44.233403', 'cluewsc_dev_eval_loss': 3.199650287628174, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-04-31_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:09:11.461253', 'csl_dev_eval_loss': 3.1439595222473145, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-06-39_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:09:15.797222', 'cluewsc_dev_eval_loss': 1.897027850151062, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-06-49_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:11:51.768949', 'csl_dev_eval_loss': 2.4851608276367188, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-09-17_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:11:52.500641', 'cluewsc_dev_eval_loss': 2.053765296936035, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-09-20_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:14:30.650753', 'cluewsc_dev_eval_loss': 2.4550085067749023, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-11-58_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:14:34.644569', 'csl_dev_eval_loss': 2.0718564987182617, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-11-58_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:16:57.536263', 'cluewsc_dev_eval_loss': 1.891601800918579, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-14-36_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*则*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:17:08.985817', 'csl_dev_eval_loss': 2.1362709999084473, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-14-38_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:19:22.757716', 'cluewsc_dev_eval_loss': 1.8409961462020874, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-17-04_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*就*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:19:41.951054', 'csl_dev_eval_loss': 3.783571243286133, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-17-14_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:21:36.773977', 'cluewsc_dev_eval_loss': 1.7284425497055054, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-19-29_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*还*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:22:16.491509', 'csl_dev_eval_loss': 2.351392984390259, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-19-47_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:23:43.603522', 'cluewsc_dev_eval_loss': 2.5799856185913086, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-21-42_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:24:48.373403', 'csl_dev_eval_loss': 3.933220863342285, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-22-22_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:25:51.578827', 'cluewsc_dev_eval_loss': 1.838315725326538, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-23-49_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*，*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:27:20.245985', 'csl_dev_eval_loss': 3.3280420303344727, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-24-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*为*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:27:59.500951', 'cluewsc_dev_eval_loss': 1.1406306028366089, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-25-57_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*，*sent_2*就*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:29:52.713153', 'csl_dev_eval_loss': 2.040168523788452, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-27-26_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:30:14.977963', 'cluewsc_dev_eval_loss': 1.3224083185195923, 'cluewsc_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-28-05_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*说*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:32:26.693091', 'csl_dev_eval_loss': 2.9418859481811523, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-29-58_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:32:35.639270', 'cluewsc_dev_eval_loss': 1.6635326147079468, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-30-20_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:35:04.931974', 'csl_dev_eval_loss': 3.053563117980957, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-32-32_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*但*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:35:09.090923', 'cluewsc_dev_eval_loss': 1.529536247253418, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-32-41_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:37:45.538698', 'csl_dev_eval_loss': 3.0079588890075684, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-35-10_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:37:46.748380', 'cluewsc_dev_eval_loss': 1.559619426727295, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-35-13_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:40:22.493746', 'cluewsc_dev_eval_loss': 1.651879906654358, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-37-52_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*与*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:40:29.110804', 'csl_dev_eval_loss': 2.2488512992858887, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-37-52_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*与*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:42:46.163550', 'cluewsc_dev_eval_loss': 1.6975114345550537, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-40-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*在*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:43:03.216227', 'csl_dev_eval_loss': 2.978652238845825, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-40-34_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:44:59.165764', 'cluewsc_dev_eval_loss': 1.713924527168274, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-42-51_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:45:35.583076', 'csl_dev_eval_loss': 3.1754496097564697, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-43-09_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:47:05.079124', 'cluewsc_dev_eval_loss': 1.402125358581543, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-45-05_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:48:07.992265', 'csl_dev_eval_loss': 3.324284076690674, 'csl_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-45-41_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*因*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:49:15.325964', 'cluewsc_dev_eval_loss': 1.5104644298553467, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-47-10_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:50:40.637676', 'csl_dev_eval_loss': 3.091632843017578, 'csl_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-48-13_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可以*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:51:22.502309', 'cluewsc_dev_eval_loss': 1.6933797597885132, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-49-20_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:53:12.900175', 'csl_dev_eval_loss': 2.438166856765747, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-50-46_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:53:35.031115', 'cluewsc_dev_eval_loss': 1.5614193677902222, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-51-28_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*说*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:55:45.382724', 'csl_dev_eval_loss': 3.415268659591675, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-53-19_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:55:56.047652', 'cluewsc_dev_eval_loss': 1.6361896991729736, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-53-40_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:58:25.547637', 'csl_dev_eval_loss': 3.4859137535095215, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-55-51_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*:*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 20:58:28.694565', 'cluewsc_dev_eval_loss': 1.694064736366272, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-56-01_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*从*sent_1*到*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:01:07.852411', 'cluewsc_dev_eval_loss': 1.679099678993225, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-58-33_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*让*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:01:07.688332', 'csl_dev_eval_loss': 2.2586448192596436, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_20-58-31_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:03:44.117338', 'cluewsc_dev_eval_loss': 1.0426825284957886, 'cluewsc_dev_eval_acc': 0.75, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-01-14_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*但*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:03:50.440416', 'csl_dev_eval_loss': 3.3393075466156006, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-01-14_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*为*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:06:08.699499', 'cluewsc_dev_eval_loss': 1.6178628206253052, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-03-49_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-21499', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*让*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:06:25.314338', 'csl_dev_eval_loss': 3.1694531440734863, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-03-55_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:08:25.002361', 'cluewsc_dev_eval_loss': 1.8648536205291748, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-06-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:08:58.850443', 'csl_dev_eval_loss': 2.2788984775543213, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-06-31_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*与*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:10:32.127589', 'cluewsc_dev_eval_loss': 3.2090165615081787, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-08-30_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:11:33.631704', 'csl_dev_eval_loss': 2.432055950164795, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-09-04_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*对*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:12:40.128080', 'cluewsc_dev_eval_loss': 1.9039782285690308, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-10-38_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:14:05.269745', 'csl_dev_eval_loss': 2.978652238845825, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-11-39_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:14:46.541571', 'cluewsc_dev_eval_loss': 1.7033733129501343, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-12-45_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:16:40.308640', 'csl_dev_eval_loss': 3.1754496097564697, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-14-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1512', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:17:01.303321', 'cluewsc_dev_eval_loss': 2.0309648513793945, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-14-52_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:19:14.122369', 'csl_dev_eval_loss': 2.9674453735351562, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-16-47_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:19:24.795488', 'cluewsc_dev_eval_loss': 2.7932231426239014, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-17-07_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:21:53.673184', 'csl_dev_eval_loss': 3.1410090923309326, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-19-20_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:21:57.363011', 'cluewsc_dev_eval_loss': 1.6314828395843506, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-19-30_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*还*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:24:33.232570', 'csl_dev_eval_loss': 3.609257936477661, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-21-59_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:24:34.517504', 'cluewsc_dev_eval_loss': 1.7317101955413818, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-22-02_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:27:10.417384', 'cluewsc_dev_eval_loss': 2.2319235801696777, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-24-39_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*好*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:27:16.547423', 'csl_dev_eval_loss': 1.8058933019638062, 'csl_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-24-39_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:29:35.328397', 'cluewsc_dev_eval_loss': 2.0103044509887695, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-27-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*说*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:29:51.303472', 'csl_dev_eval_loss': 2.2095580101013184, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-27-21_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*的*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:31:49.343708', 'cluewsc_dev_eval_loss': 1.8704099655151367, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-29-40_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:32:23.095624', 'csl_dev_eval_loss': 3.364102363586426, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-29-57_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:33:57.078000', 'cluewsc_dev_eval_loss': 1.962895393371582, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-31-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*又*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:34:54.789687', 'csl_dev_eval_loss': 1.3945817947387695, 'csl_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-32-29_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:36:09.836035', 'cluewsc_dev_eval_loss': 2.464827060699463, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-34-03_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*好*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:37:29.502949', 'csl_dev_eval_loss': 1.9691781997680664, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-35-00_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:38:14.916530', 'cluewsc_dev_eval_loss': 1.3971052169799805, 'cluewsc_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-36-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*来*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:40:03.605325', 'csl_dev_eval_loss': 2.477950096130371, 'csl_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-37-35_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*:*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:40:24.953026', 'cluewsc_dev_eval_loss': 2.2918808460235596, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-38-20_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*，*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:42:37.798811', 'csl_dev_eval_loss': 3.622392177581787, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-40-09_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:42:46.455688', 'cluewsc_dev_eval_loss': 2.5634241104125977, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-40-30_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:45:18.060870', 'csl_dev_eval_loss': 1.551183819770813, 'csl_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-42-43_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:45:21.366878', 'cluewsc_dev_eval_loss': 2.6423215866088867, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-42-51_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:47:55.835312', 'cluewsc_dev_eval_loss': 2.4257965087890625, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-45-26_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:47:59.484843', 'csl_dev_eval_loss': 2.736549139022827, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-45-24_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:50:22.855598', 'cluewsc_dev_eval_loss': 2.53757381439209, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-48-01_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*与*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:50:36.471981', 'csl_dev_eval_loss': 2.3712964057922363, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-48-03_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:52:39.420798', 'cluewsc_dev_eval_loss': 2.4826369285583496, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-50-28_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:53:09.857161', 'csl_dev_eval_loss': 2.2075018882751465, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-50-42_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*对*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:54:44.529246', 'cluewsc_dev_eval_loss': 2.6304261684417725, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-52-44_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*在*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:55:42.903124', 'csl_dev_eval_loss': 1.7816436290740967, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-53-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:56:53.243047', 'cluewsc_dev_eval_loss': 2.3959381580352783, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-54-50_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:58:15.132285', 'csl_dev_eval_loss': 1.222744345664978, 'csl_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-55-48_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*,*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 21:59:01.966913', 'cluewsc_dev_eval_loss': 2.382816791534424, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-56-58_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*，*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:00:48.534820', 'csl_dev_eval_loss': 2.470795154571533, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-58-21_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:01:11.806983', 'cluewsc_dev_eval_loss': 2.5091347694396973, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_21-59-07_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:03:20.931972', 'csl_dev_eval_loss': 1.7314038276672363, 'csl_dev_eval_acc': 0.71875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-00-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*与*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:03:32.263279', 'cluewsc_dev_eval_loss': 2.3716280460357666, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-01-17_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:06:04.607603', 'csl_dev_eval_loss': 2.014862298965454, 'csl_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-03-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:06:05.214255', 'cluewsc_dev_eval_loss': 2.526550769805908, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-03-37_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*说*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:08:39.037508', 'cluewsc_dev_eval_loss': 2.506610870361328, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-06-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:08:46.707072', 'csl_dev_eval_loss': 2.9109911918640137, 'csl_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-06-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*对*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:11:01.667029', 'cluewsc_dev_eval_loss': 2.7767820358276367, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-08-44_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*让*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:11:21.133291', 'csl_dev_eval_loss': 3.0097928047180176, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-08-52_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:13:13.844956', 'cluewsc_dev_eval_loss': 2.5718798637390137, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-11-07_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*让*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:13:50.835994', 'csl_dev_eval_loss': 2.67096209526062, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-11-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*定*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:15:21.289524', 'cluewsc_dev_eval_loss': 2.216737747192383, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-13-19_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-17381', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0**sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:16:22.411144', 'csl_dev_eval_loss': 1.8123207092285156, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-13-56_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*定*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:17:32.419055', 'cluewsc_dev_eval_loss': 3.785370349884033, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-15-28_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:18:54.902690', 'csl_dev_eval_loss': 3.1410090923309326, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-16-28_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:19:43.225995', 'cluewsc_dev_eval_loss': 3.1292903423309326, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-17-37_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:21:27.774799', 'csl_dev_eval_loss': 3.609257936477661, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-19-00_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:21:51.210319', 'cluewsc_dev_eval_loss': 4.007004737854004, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-19-48_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:24:00.052629', 'csl_dev_eval_loss': 3.364102363586426, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-21-33_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可能*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:24:11.689621', 'cluewsc_dev_eval_loss': 6.03596830368042, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-21-56_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:26:41.327927', 'csl_dev_eval_loss': 1.8058933019638062, 'csl_dev_eval_acc': 0.65625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-24-06_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:26:43.612618', 'cluewsc_dev_eval_loss': 3.71807599067688, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-24-17_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*还*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:29:22.335252', 'cluewsc_dev_eval_loss': 3.004030704498291, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-26-48_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:29:25.440445', 'csl_dev_eval_loss': 2.2095580101013184, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-26-47_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*的*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:31:49.348486', 'cluewsc_dev_eval_loss': 4.434671401977539, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-29-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:32:03.881732', 'csl_dev_eval_loss': 1.9691781997680664, 'csl_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-29-30_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-23408', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:34:05.181876', 'cluewsc_dev_eval_loss': 3.1363377571105957, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-31-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:34:36.338743', 'csl_dev_eval_loss': 4.100913047790527, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-32-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*，*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:36:18.512140', 'cluewsc_dev_eval_loss': 3.2641212940216064, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-34-10_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*则*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:37:05.160911', 'csl_dev_eval_loss': 4.276721477508545, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-34-42_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*,*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:38:27.027706', 'cluewsc_dev_eval_loss': 2.924262762069702, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-36-24_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*说*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:39:37.306355', 'csl_dev_eval_loss': 3.532339572906494, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-37-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:40:37.124275', 'cluewsc_dev_eval_loss': 3.2150073051452637, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-38-32_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:42:09.861128', 'csl_dev_eval_loss': 2.9944214820861816, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-39-43_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:42:43.196964', 'cluewsc_dev_eval_loss': 2.705223560333252, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-40-43_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*又*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:44:43.704018', 'csl_dev_eval_loss': 3.3391711711883545, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-42-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:45:00.066233', 'cluewsc_dev_eval_loss': 3.7017290592193604, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-42-48_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*，*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:47:17.145075', 'csl_dev_eval_loss': 2.9347500801086426, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-44-49_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*的*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:47:26.279017', 'cluewsc_dev_eval_loss': 4.638655662536621, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-45-05_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*好*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:49:56.430910', 'csl_dev_eval_loss': 5.380801200866699, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-47-23_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*因*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:49:59.429172', 'cluewsc_dev_eval_loss': 4.063093662261963, 'cluewsc_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-47-31_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*，*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:52:39.417828', 'cluewsc_dev_eval_loss': 2.9616007804870605, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-50-04_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:52:39.227620', 'csl_dev_eval_loss': 4.354430198669434, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-50-02_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*以*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:55:14.649595', 'cluewsc_dev_eval_loss': 3.095201015472412, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-52-45_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:55:21.554479', 'csl_dev_eval_loss': 3.6300668716430664, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-52-45_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:57:36.670725', 'cluewsc_dev_eval_loss': 3.150491237640381, 'cluewsc_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-55-19_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:57:55.765717', 'csl_dev_eval_loss': 2.868522882461548, 'csl_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-55-26_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 22:59:47.885689', 'cluewsc_dev_eval_loss': 2.9050326347351074, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-57-42_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:00:28.532506', 'csl_dev_eval_loss': 3.8783061504364014, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-58-01_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*:*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:01:57.586398', 'cluewsc_dev_eval_loss': 3.224757671356201, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_22-59-53_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*与*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:03:02.859923', 'csl_dev_eval_loss': 3.1288769245147705, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-00-34_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:04:08.560725', 'cluewsc_dev_eval_loss': 2.9625988006591797, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-02-03_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:05:35.488715', 'csl_dev_eval_loss': 4.727847099304199, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-03-08_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:06:19.752011', 'cluewsc_dev_eval_loss': 2.849639654159546, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-04-14_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*在*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:08:09.604717', 'csl_dev_eval_loss': 6.2216315269470215, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-05-41_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*由*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:08:30.648443', 'cluewsc_dev_eval_loss': 3.2332637310028076, 'cluewsc_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-06-25_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:10:46.844728', 'csl_dev_eval_loss': 2.8489315509796143, 'csl_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-08-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*有*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:10:54.525499', 'cluewsc_dev_eval_loss': 2.9682655334472656, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-08-36_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:13:26.133586', 'csl_dev_eval_loss': 5.4473652839660645, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-10-52_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask**+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:13:29.439806', 'cluewsc_dev_eval_loss': 3.0461840629577637, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-10-59_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*从*sent_1*到*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:16:05.231321', 'cluewsc_dev_eval_loss': 3.104069948196411, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-13-34_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:16:07.414102', 'csl_dev_eval_loss': 3.165458917617798, 'csl_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-13-32_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:18:36.280083', 'cluewsc_dev_eval_loss': 2.202359199523926, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-16-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*但*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:18:45.614268', 'csl_dev_eval_loss': 3.5160529613494873, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-16-12_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*,*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:20:59.169938', 'cluewsc_dev_eval_loss': 3.581956386566162, 'cluewsc_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-18-41_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*那*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:21:18.424176', 'csl_dev_eval_loss': 4.128390312194824, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-18-51_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*为*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:23:09.835617', 'cluewsc_dev_eval_loss': 3.1857547760009766, 'cluewsc_dev_eval_acc': 0.40625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-21-04_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0**sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:23:52.095163', 'csl_dev_eval_loss': 4.183300971984863, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-21-24_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*对*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:25:17.139498', 'cluewsc_dev_eval_loss': 3.2401607036590576, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-23-15_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-482', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*的*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:26:27.750110', 'csl_dev_eval_loss': 4.091540336608887, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-23-57_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*与*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:27:27.388452', 'cluewsc_dev_eval_loss': 2.3471639156341553, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-25-24_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:29:00.571178', 'csl_dev_eval_loss': 2.6297242641448975, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-26-33_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*?*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:29:33.215122', 'cluewsc_dev_eval_loss': 2.1199753284454346, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-27-33_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*却*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 1, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:31:33.944727', 'csl_dev_eval_loss': 3.040294647216797, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-29-06_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*在*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:31:49.220422', 'cluewsc_dev_eval_loss': 2.124781370162964, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-29-38_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 2, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:34:10.847144', 'csl_dev_eval_loss': 3.3667097091674805, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-31-39_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*对*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:34:19.009465', 'cluewsc_dev_eval_loss': 1.8492205142974854, 'cluewsc_dev_eval_acc': 0.625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-31-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*还*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 3, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:36:49.980072', 'csl_dev_eval_loss': 3.2243568897247314, 'csl_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-34-17_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*定*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:36:52.799898', 'cluewsc_dev_eval_loss': 2.367187023162842, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-34-24_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*不*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 4, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:39:26.251400', 'cluewsc_dev_eval_loss': 2.6365914344787598, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-36-57_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 5, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:39:32.936374', 'csl_dev_eval_loss': 5.02816104888916, 'csl_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-36-55_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*定*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:41:51.857171', 'cluewsc_dev_eval_loss': 3.3917675018310547, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-39-31_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 6, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:42:07.733782', 'csl_dev_eval_loss': 3.532339572906494, 'csl_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-39-37_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*：*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:44:07.331101', 'cluewsc_dev_eval_loss': 3.0039942264556885, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-41-57_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 7, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:44:38.443973', 'csl_dev_eval_loss': 2.9944214820861816, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-42-13_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:46:13.421943', 'cluewsc_dev_eval_loss': 3.7616467475891113, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-44-13_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*就*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 8, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:47:15.257837', 'csl_dev_eval_loss': 3.3391711711883545, 'csl_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-44-44_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:48:23.140164', 'cluewsc_dev_eval_loss': 3.0731277465820312, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-46-19_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*就*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 9, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:49:47.729650', 'csl_dev_eval_loss': 5.380801200866699, 'csl_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-47-21_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21877', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。这*mask*因*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:50:15.694743', 'cluewsc_dev_eval_loss': 2.256795883178711, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-48-28_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*还*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 10, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:51:23.848947', 'cluewsc_dev_eval_loss': 2.195411443710327, 'cluewsc_dev_eval_acc': 0.46875, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-50-19_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*也*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 11, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:52:32.308336', 'cluewsc_dev_eval_loss': 2.70182204246521, 'cluewsc_dev_eval_acc': 0.4375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-51-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*又*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 12, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:53:41.879595', 'cluewsc_dev_eval_loss': 3.2460098266601562, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-52-36_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*说*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 13, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:54:50.026214', 'cluewsc_dev_eval_loss': 4.661990165710449, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-53-45_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*，*sent_2*就*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 14, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:55:58.478878', 'cluewsc_dev_eval_loss': 2.5513999462127686, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-54-53_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 15, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:57:08.443659', 'cluewsc_dev_eval_loss': 3.096813201904297, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-56-02_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 16, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:58:17.226885', 'cluewsc_dev_eval_loss': 2.435727596282959, 'cluewsc_dev_eval_acc': 0.5, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-57-12_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 17, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-29 23:59:25.804480', 'cluewsc_dev_eval_loss': 2.5533015727996826, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-58-21_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*与*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 18, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:00:34.360062', 'cluewsc_dev_eval_loss': 2.9677515029907227, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul29_23-59-29_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*但*mask*，*sent_0*而*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 19, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:01:42.560169', 'cluewsc_dev_eval_loss': 2.46696138381958, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-00-38_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 20, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:02:50.538048', 'cluewsc_dev_eval_loss': 2.7336740493774414, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-01-46_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*在*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 21, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:03:59.053331', 'cluewsc_dev_eval_loss': 2.5016064643859863, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-02-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*是*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 22, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:05:07.558613', 'cluewsc_dev_eval_loss': 2.7131597995758057, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-04-03_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*那*sent_1*和*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 23, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:06:15.627614', 'cluewsc_dev_eval_loss': 2.571993827819824, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-05-11_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 24, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:07:23.644529', 'cluewsc_dev_eval_loss': 2.5758938789367676, 'cluewsc_dev_eval_acc': 0.59375, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-06-19_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*让*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 25, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:08:32.636430', 'cluewsc_dev_eval_loss': 2.4690887928009033, 'cluewsc_dev_eval_acc': 0.53125, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-07-27_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 26, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:09:41.855703', 'cluewsc_dev_eval_loss': 2.519484043121338, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-08-36_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*而*sent_1*说*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 27, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:10:50.783168', 'cluewsc_dev_eval_loss': 2.5736002922058105, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-09-45_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*但*mask*，*sent_0*而*sent_1*，*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 28, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:12:02.012017', 'cluewsc_dev_eval_loss': 3.1481425762176514, 'cluewsc_dev_eval_acc': 0.5625, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': False, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 300, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-10-55_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 100, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-12510', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': True, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*可*mask*，*sent_0*但*sent_1*对*sent_2**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13-clean.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 29, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': 'exp-template', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:32:24.131151', 'eprstmt_dev_eval_loss': 1.136286735534668, 'eprstmt_dev_eval_acc': 0.875, 'eprstmt_test_eval_loss': 1.3276163339614868, 'eprstmt_test_eval_acc': 0.8442622950819673, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7869', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-31-03_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-7869', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/1/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/1/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:33:49.275026', 'eprstmt_dev_eval_loss': 1.5534191131591797, 'eprstmt_dev_eval_acc': 0.78125, 'eprstmt_test_eval_loss': 1.2056388854980469, 'eprstmt_test_eval_acc': 0.8573770491803279, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-3926', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-32-29_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-3926', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/2/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/2/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:35:15.312442', 'eprstmt_dev_eval_loss': 1.311348795890808, 'eprstmt_dev_eval_acc': 0.84375, 'eprstmt_test_eval_loss': 1.4442248344421387, 'eprstmt_test_eval_acc': 0.8557377049180328, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-3357', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-33-54_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-3357', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/3/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/3/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 00:36:41.217268', 'eprstmt_dev_eval_loss': 0.43852001428604126, 'eprstmt_dev_eval_acc': 0.96875, 'eprstmt_test_eval_loss': 1.3258419036865234, 'eprstmt_test_eval_acc': 0.8622950819672132, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-8034', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_00-35-20_0cffd885d1e0', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/eprstmt-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-8034', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'eprstmt', 'data_dir': 'data/k-shot/4/eprstmt/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*很*mask*，*+sent_0**sep+*', 'mapping': "{'Negative':'差','Positive':'好'}", 'template_path': 'my_auto_template/4/eprstmt/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:00:36.644066', 'bustm_dev_eval_loss': 1.0792187452316284, 'bustm_dev_eval_acc': 0.71875, 'bustm_test_eval_loss': 1.9140291213989258, 'bustm_test_eval_acc': 0.582392776523702, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-17121', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_22-57-53_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-17121', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/1/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/1/bustm/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:02:41.653469', 'ocnli_dev_eval_loss': 2.546208381652832, 'ocnli_dev_eval_acc': 0.5, 'ocnli_test_eval_loss': 2.758917808532715, 'ocnli_test_eval_acc': 0.4246031746031746, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-15692', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_22-59-11_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-15692', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/1/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': "{'contradiction':'不','neutral':'或','entailment':'是'}", 'template_path': 'my_auto_template/1/ocnli/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:04:20.390236', 'bustm_dev_eval_loss': 1.1480728387832642, 'bustm_dev_eval_acc': 0.625, 'bustm_test_eval_loss': 2.3726892471313477, 'bustm_test_eval_acc': 0.5976297968397292, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24758', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-00-54_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24758', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/2/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*，*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/bustm/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:06:34.939111', 'ocnli_dev_eval_loss': 3.174647331237793, 'ocnli_dev_eval_acc': 0.53125, 'ocnli_test_eval_loss': 3.1670453548431396, 'ocnli_test_eval_acc': 0.4126984126984127, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-30945', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-03-04_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-30945', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/2/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*。*mask*是*+sentl_1**sep+*', 'mapping': "{'contradiction':'不','neutral':'或','entailment':'是'}", 'template_path': 'my_auto_template/2/ocnli/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:08:05.238508', 'bustm_dev_eval_loss': 2.3101439476013184, 'bustm_dev_eval_acc': 0.59375, 'bustm_test_eval_loss': 2.4668149948120117, 'bustm_test_eval_acc': 0.5632054176072234, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-31481', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-04-37_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-31481', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/3/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/bustm/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:10:29.465937', 'ocnli_dev_eval_loss': 4.077347278594971, 'ocnli_dev_eval_acc': 0.34375, 'ocnli_test_eval_loss': 3.549421787261963, 'ocnli_test_eval_acc': 0.38015873015873014, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4489', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-06-58_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-4489', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/3/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': "{'contradiction':'不','neutral':'或','entailment':'是'}", 'template_path': 'my_auto_template/3/ocnli/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:11:49.098132', 'bustm_dev_eval_loss': 1.6529942750930786, 'bustm_dev_eval_acc': 0.5625, 'bustm_test_eval_loss': 2.219305992126465, 'bustm_test_eval_acc': 0.5440180586907449, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-31691', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-08-22_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/bustm-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-31691', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'bustm', 'data_dir': 'data/k-shot/4/bustm/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*可*mask*。*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/bustm/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:13:15.021436', 'ocnli_dev_eval_loss': 3.615640640258789, 'ocnli_dev_eval_acc': 0.3125, 'ocnli_test_eval_loss': 3.5358996391296387, 'ocnli_test_eval_acc': 0.36666666666666664, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21968', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-10-52_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/ocnli-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-21968', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'ocnli', 'data_dir': 'data/k-shot/4/ocnli/16-13', 'max_seq_length': 140, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*就*mask*说*+sentl_1**sep+*', 'mapping': "{'contradiction':'不','neutral':'或','entailment':'是'}", 'template_path': 'my_auto_template/4/ocnli/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': 64, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:19:36.198600', 'tnews_dev_eval_loss': 9.118578910827637, 'tnews_dev_eval_acc': 0.5333333333333333, 'tnews_test_eval_loss': 8.366179466247559, 'tnews_test_eval_acc': 0.5323383084577115, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-28808', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-16-15_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-28808', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/1/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/1/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:22:17.255200', 'csldcp_dev_eval_loss': 4.5097222328186035, 'csldcp_dev_eval_acc': 0.5708955223880597, 'csldcp_test_eval_loss': 4.7686662673950195, 'csldcp_test_eval_acc': 0.5397982062780269, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-9048', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-14-40_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-9048', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/1/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*网*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/1/csldcp/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:23:27.624900', 'tnews_dev_eval_loss': 7.664968013763428, 'tnews_dev_eval_acc': 0.55, 'tnews_test_eval_loss': 7.204716682434082, 'tnews_test_eval_acc': 0.5303482587064676, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1463', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-19-53_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-1463', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/2/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/2/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:26:58.497552', 'tnews_dev_eval_loss': 6.482001781463623, 'tnews_dev_eval_acc': 0.49583333333333335, 'tnews_test_eval_loss': 6.780868053436279, 'tnews_test_eval_acc': 0.5119402985074627, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-28938', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-23-38_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-28938', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/3/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/3/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:30:34.196276', 'tnews_dev_eval_loss': 7.046708583831787, 'tnews_dev_eval_acc': 0.5208333333333334, 'tnews_test_eval_loss': 6.359518051147461, 'tnews_test_eval_acc': 0.5029850746268657, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-11878', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-27-15_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/tnews-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-11878', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'tnews', 'data_dir': 'data/k-shot/4/tnews/16-13', 'max_seq_length': 70, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*好*mask*mask*！*sep+*', 'mapping': "{100:'故事',101:'文化',102:'娱乐',103:'体育',104:'财经',106:'房产',107:'汽车',108:'教育',109:'科技',110:'军事',112:'旅游',113:'国际',114:'股票',115:'农业',116:'电竞'}", 'template_path': 'my_auto_template/4/tnews/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 64, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:31:32.687579', 'csldcp_dev_eval_loss': 4.905233860015869, 'csldcp_dev_eval_acc': 0.5223880597014925, 'csldcp_test_eval_loss': 4.8408989906311035, 'csldcp_test_eval_acc': 0.5190582959641256, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-29835', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-23-20_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-29835', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/2/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*会*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/2/csldcp/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:37:30.091222', 'csldcp_dev_eval_loss': 4.730878829956055, 'csldcp_dev_eval_acc': 0.5167910447761194, 'csldcp_test_eval_loss': 4.797718524932861, 'csldcp_test_eval_acc': 0.5145739910313901, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-32155', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-32-18_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-32155', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/3/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*界*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/3/csldcp/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-30 23:43:27.598412', 'csldcp_dev_eval_loss': 4.473974227905273, 'csldcp_dev_eval_acc': 0.539179104477612, 'csldcp_test_eval_loss': 4.6400370597839355, 'csldcp_test_eval_acc': 0.5504484304932735, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-32468', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-38-15_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csldcp-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-32468', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csldcp', 'data_dir': 'data/k-shot/4/csldcp/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*中国*mask*mask*界*+sent_0**sep+*', 'mapping': "{'材料科学与工程':'材料','作物学':'作物','口腔医学':'口腔','药学':'药学','教育学':'教育','水利工程':'水利','理论经济学':'理经','食品科学与工程':'食品','畜牧学/兽医学':'兽医','体育学':'体育','核科学与技术':'核能','力学':'力学','园艺学':'园艺','水产':'水产','法学':'法学','地质学/地质资源与地质工程':'地质','石油与天然气工程':'能源','农林经济管理':'农林','信息与通信工程':'通信','图书馆、情报与档案管理':'情报','政治学':'政治','电气工程':'电气','海洋科学':'海洋','民族学':'民族','航空宇航科学与技术':'航空','化学/化学工程与技术':'化工','哲学':'哲学','公共卫生与预防医学':'卫生','艺术学':'艺术','农业工程':'农工','船舶与海洋工程':'船舶','计算机科学与技术':'计科','冶金工程':'冶金','交通运输工程':'交通','动力工程及工程热物理':'动力','纺织科学与工程':'纺织','建筑学':'建筑','环境科学与工程':'环境','公共管理':'公管','数学':'数学','物理学':'物理','林学/林业工程':'林业','心理学':'心理','历史学':'历史','工商管理':'工商','应用经济学':'应经','中医学/中药学':'中医','天文学':'天文','机械工程':'机械','土木工程':'土木','光学工程':'光学','地理学':'地理','农业资源利用':'农资','生物学/生物科学与工程':'生物','兵器科学与技术':'兵器','矿业工程':'矿业','大气科学':'大气','基础医学/临床医学':'医学','电子科学与技术':'电子','测绘科学与技术':'测绘','控制科学与工程':'控制','军事学':'军事','中国语言文学':'语言','新闻传播学':'新闻','社会学':'社会','地球物理学':'地球','植物保护':'植物'}", 'template_path': 'my_auto_template/4/csldcp/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:04:38.641720', 'cluewsc_dev_eval_loss': 1.5500901937484741, 'cluewsc_dev_eval_acc': 0.71875, 'cluewsc_test_eval_loss': 2.604602336883545, 'cluewsc_test_eval_acc': 0.5706967213114754, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19587', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul30_23-59-11_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-19587', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/1/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*但*sent_1*对*sent_2*说*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/1/cluewsc/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:09:24.224995', 'iflytek_dev_eval_loss': 2.821451187133789, 'iflytek_dev_eval_acc': 0.48840579710144927, 'iflytek_test_eval_loss': 2.899552583694458, 'iflytek_test_eval_acc': 0.4665523156089194, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18592', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-00-08_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-1-16-13-hfl/chinese-roberta-wwm-ext-18592', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/1/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*。*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/1/iflytek/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:12:08.513231', 'cluewsc_dev_eval_loss': 3.2045371532440186, 'cluewsc_dev_eval_acc': 0.46875, 'cluewsc_test_eval_loss': 3.402925491333008, 'cluewsc_test_eval_acc': 0.4948770491803279, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13776', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-05-01_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-13776', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/2/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*对*sent_2*，*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/2/cluewsc/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:20:22.870870', 'cluewsc_dev_eval_loss': 4.773619651794434, 'cluewsc_dev_eval_acc': 0.5625, 'cluewsc_test_eval_loss': 4.5107102394104, 'cluewsc_test_eval_acc': 0.5194672131147541, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-10526', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-12-29_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-10526', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/3/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*，*sent_2*可*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/3/cluewsc/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:19:43.331133', 'iflytek_dev_eval_loss': 2.640763759613037, 'iflytek_dev_eval_acc': 0.518840579710145, 'iflytek_test_eval_loss': 2.8972365856170654, 'iflytek_test_eval_acc': 0.4505431675242996, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-16359', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-10-30_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-16359', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/2/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/2/iflytek/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:27:55.010003', 'cluewsc_dev_eval_loss': 4.433286666870117, 'cluewsc_dev_eval_acc': 0.46875, 'cluewsc_test_eval_loss': 5.2768120765686035, 'cluewsc_test_eval_acc': 0.5061475409836066, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-1936', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-20-52_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/cluewsc-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-1936', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'cluewsc', 'data_dir': 'data/k-shot/4/cluewsc/16-13', 'max_seq_length': 300, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent_0*而*sent_1*，*sent_2*就*mask**sep+*', 'mapping': "{False:'否',True:'是'}", 'template_path': 'my_auto_template/4/cluewsc/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 256, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:29:29.183806', 'iflytek_dev_eval_loss': 2.382788896560669, 'iflytek_dev_eval_acc': 0.5173913043478261, 'iflytek_test_eval_loss': 2.634643077850342, 'iflytek_test_eval_acc': 0.465980560320183, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-1500', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-20-54_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-1500', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/3/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*！*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/3/iflytek/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:35:50.490363', 'iflytek_dev_eval_loss': 2.620736598968506, 'iflytek_dev_eval_acc': 0.5072463768115942, 'iflytek_test_eval_loss': 2.8116955757141113, 'iflytek_test_eval_acc': 0.4602630074328187, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-25346', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-30-16_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/iflytek-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-25346', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'iflytek', 'data_dir': 'data/k-shot/4/iflytek/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls*.*mask*mask*。*+sent_0**sep+*', 'mapping': "{0:'打车',100:'美颜',101:'影像',102:'摄影',103:'相机',104:'绘画',105:'二手',106:'电商',107:'团购',108:'外卖',109:'票务',10:'社区',110:'超市',111:'购物',112:'笔记',113:'办公',114:'日程',115:'女性',116:'经营',117:'收款',118:'其他',11:'赚钱',12:'魔幻',13:'仙侠',14:'卡牌',15:'飞行',16:'射击',17:'休闲',18:'动作',19:'体育',1:'地图',20:'棋牌',21:'养成',22:'策略',23:'竞技',24:'辅助',25:'约会',26:'通讯',27:'工作',28:'论坛',29:'婚恋',2:'免费',30:'情侣',31:'社交',32:'生活',33:'博客',34:'新闻',35:'漫画',36:'小说',37:'技术',38:'教辅',39:'问答',3:'租车',40:'搞笑',41:'杂志',42:'百科',43:'影视',44:'求职',45:'兼职',46:'视频',47:'短视',48:'音乐',49:'直播',4:'同城',50:'电台',51:'唱歌',52:'两性',53:'小学',54:'职考',55:'公务',56:'英语',57:'在线',58:'教育',59:'成人',5:'快递',60:'艺术',61:'语言',62:'旅游',63:'预定',64:'民航',65:'铁路',66:'酒店',67:'行程',68:'民宿',69:'出国',6:'婚庆',70:'工具',71:'亲子',72:'母婴',73:'驾校',74:'违章',75:'汽车',76:'买车',77:'养车',78:'行车',79:'租房',7:'家政',80:'买房',81:'装修',82:'电子',83:'挂号',84:'养生',85:'医疗',86:'减肥',87:'美妆',88:'菜谱',89:'餐饮',8:'交通',90:'资讯',91:'运动',92:'支付',93:'保险',94:'股票',95:'借贷',96:'理财',97:'彩票',98:'记账',99:'银行',9:'政务'}", 'template_path': 'my_auto_template/4/iflytek/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:41:05.504188', 'csl_dev_eval_loss': 3.6329915523529053, 'csl_dev_eval_acc': 0.59375, 'csl_test_eval_loss': 4.644564151763916, 'csl_test_eval_acc': 0.5369978858350951, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24693', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-35-23_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-2-16-13-hfl/chinese-roberta-wwm-ext-24693', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/2/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*是*mask*是*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/2/csl/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:46:43.818849', 'csl_dev_eval_loss': 3.8077778816223145, 'csl_dev_eval_acc': 0.46875, 'csl_test_eval_loss': 4.060720920562744, 'csl_test_eval_acc': 0.5035236081747709, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-16430', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-42-00_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-3-16-13-hfl/chinese-roberta-wwm-ext-16430', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/3/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*而不*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/3/csl/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
{'time': '2021-07-31 00:52:24.139454', 'csl_dev_eval_loss': 3.4921255111694336, 'csl_dev_eval_acc': 0.59375, 'csl_test_eval_loss': 3.4030425548553467, 'csl_test_eval_acc': 0.5084566596194503, 'model_name_or_path': 'hfl/chinese-roberta-wwm-ext', 'config_name': None, 'tokenizer_name': None, 'cache_dir': None, 'few_shot_type': 'prompt', 'random_segment': False, 'output_dir': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7230', 'overwrite_output_dir': True, 'do_train': True, 'do_eval': True, 'do_predict': True, 'evaluate_during_training': True, 'prediction_loss_only': False, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'per_gpu_train_batch_size': None, 'per_gpu_eval_batch_size': None, 'gradient_accumulation_steps': 1, 'eval_accumulation_steps': None, 'learning_rate': 1e-05, 'weight_decay': 0.0, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3.0, 'max_steps': 1000, 'warmup_steps': 0, 'logging_dir': 'runs/Jul31_00-47-38_8590f5fab899', 'logging_first_step': False, 'logging_steps': 500, 'save_steps': 500, 'save_total_limit': None, 'no_cuda': False, 'seed': 13, 'fp16': False, 'fp16_opt_level': 'O1', 'local_rank': -1, 'tpu_num_cores': None, 'tpu_metrics_debug': False, 'debug': False, 'dataloader_drop_last': False, 'eval_steps': 300, 'dataloader_num_workers': 0, 'past_index': -1, 'run_name': 'result/csl-prompt-4-16-13-hfl/chinese-roberta-wwm-ext-7230', 'disable_tqdm': False, 'remove_unused_columns': True, 'label_names': None, 'load_best_model_at_end': False, 'metric_for_best_model': None, 'greater_is_better': None, 'array_id': -1, 'model_id': -1, 'save_logit': False, 'save_logit_dir': None, 'fix_layers': 0, 'save_at_last': False, 'no_train': False, 'no_predict': False, '__cached__setup_devices': (device(type='cuda', index=0), 1), 'task_name': 'csl', 'data_dir': 'data/k-shot/4/csl/16-13', 'max_seq_length': 512, 'overwrite_cache': False, 'num_k': 16, 'num_sample': 16, 'num_demo': 1, 'auto_demo': True, 'template': '*cls**sent-_0*特别*mask*.*+sentl_1**sep+*', 'mapping': "{0:'否',1:'是'}", 'template_path': 'my_auto_template/4/csl/16-13.sort.txt', 'mapping_path': None, 'prompt_path': None, 'template_id': 0, 'mapping_id': None, 'prompt_id': None, 'top_n_template': None, 'tag': '', 'demo_filter': False, 'demo_filter_rate': 0.5, 'demo_filter_model': None, 'debug_mode': False, 'double_demo': False, 'first_sent_limit': 500, 'other_sent_limit': None, 'use_full_length': False, 'gpt3_in_context_head': False, 'gpt3_in_context_tail': False, 'gpt3_in_context_num': 32, 'truncate_head': False, 'prompt': True, 'template_list': None}
