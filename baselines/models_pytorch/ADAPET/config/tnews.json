{
    "pretrained_weight":  "hfl/chinese-roberta-wwm-ext",
    "dataset": "tnews",
    "max_text_length": 64,
    "batch_size": 8,
    "eval_batch_size": 1,
    "num_batches": 100,
    "max_num_lbl_tok": 2,
    "eval_every": 6,
    "warmup_ratio": 0.06,
    "mask_alpha": 0.105,
    "grad_accumulation_factor": 16,
    "seed": 43,
    "lr": 1e-5,
    "weight_decay": 1e-2,
    "pattern": 1,
    "eval_train": true
}
